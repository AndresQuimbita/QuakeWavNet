{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (4.17.0)\n",
      "Requirement already satisfied: filelock in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: sacremoses in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: six in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sacremoses->transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sacremoses->transformers) (1.3.1)\n",
      "Requirement already satisfied: ipywidgets in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (8.0.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipywidgets) (6.23.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: packaging in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
      "Requirement already satisfied: psutil in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
      "Requirement already satisfied: backcall in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.5.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (6.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (3.15.0)\n",
      "Collecting pytorch-lightning==1.5.10\n",
      "  Using cached pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (1.22.4)\n",
      "Requirement already satisfied: torch>=1.7.* in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (2.0.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (0.18.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (6.0)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (2023.6.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (2.13.0)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (0.11.4)\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (0.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (23.1)\n",
      "Requirement already satisfied: typing-extensions in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (4.5.0)\n",
      "Requirement already satisfied: setuptools==59.5.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (59.5.0)\n",
      "Requirement already satisfied: requests in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (3.8.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.56.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.4.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (4.23.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.40.0)\n",
      "Requirement already satisfied: filelock in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (3.12.2)\n",
      "Requirement already satisfied: sympy in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (1.12)\n",
      "Requirement already satisfied: networkx in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.7.*->pytorch-lightning==1.5.10) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.7.*->pytorch-lightning==1.5.10) (16.0.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (6.7.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sympy->torch>=1.7.*->pytorch-lightning==1.5.10) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.2.2)\n",
      "Installing collected packages: pytorch-lightning\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.9.5\n",
      "    Uninstalling pytorch-lightning-1.9.5:\n",
      "      Successfully uninstalled pytorch-lightning-1.9.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lightning-bolts 0.7.0 requires pytorch-lightning<2.0.0,>1.7.0, but you have pytorch-lightning 1.5.10 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pytorch-lightning-1.5.10\n",
      "Requirement already satisfied: nvidia-ml-py3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (7.352.0)\n",
      "Requirement already satisfied: neptune-client in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (1.3.1)\n",
      "Requirement already satisfied: GitPython>=2.0.8 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (3.1.31)\n",
      "Requirement already satisfied: Pillow>=1.1.6 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (9.5.0)\n",
      "Requirement already satisfied: PyJWT in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (2.7.0)\n",
      "Requirement already satisfied: boto3>=1.16.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.26.165)\n",
      "Requirement already satisfied: bravado<12.0.0,>=11.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (11.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (8.1.3)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (0.18.3)\n",
      "Requirement already satisfied: oauthlib>=2.1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (3.2.2)\n",
      "Requirement already satisfied: packaging in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (23.1)\n",
      "Requirement already satisfied: pandas in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.2.4)\n",
      "Requirement already satisfied: psutil in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (5.9.5)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib>=1.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.3.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.16.0)\n",
      "Requirement already satisfied: swagger-spec-validator>=2.7.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (3.0.3)\n",
      "Requirement already satisfied: urllib3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.26.16)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.6.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.165 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (1.29.165)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (0.6.1)\n",
      "Requirement already satisfied: bravado-core>=5.16.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (5.17.1)\n",
      "Requirement already satisfied: msgpack in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.0.5)\n",
      "Requirement already satisfied: python-dateutil in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0)\n",
      "Requirement already satisfied: simplejson in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (3.19.1)\n",
      "Requirement already satisfied: monotonic in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.6)\n",
      "Requirement already satisfied: typing-extensions in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (4.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from GitPython>=2.0.8->neptune-client) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (2023.5.7)\n",
      "Requirement already satisfied: jsonschema in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.17.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pandas->neptune-client) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pandas->neptune-client) (1.22.4)\n",
      "Requirement already satisfied: jsonref in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (5.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.19.3)\n",
      "Requirement already satisfied: fqdn in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (2.4)\n",
      "Requirement already satisfied: rfc3339-validator in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.1.4)\n",
      "Requirement already satisfied: rfc3987 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.3.8)\n",
      "Requirement already satisfied: uri-template in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.3)\n",
      "Requirement already satisfied: lightning-bolts in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-bolts) (1.22.4)\n",
      "Collecting pytorch-lightning<2.0.0,>1.7.0 (from lightning-bolts)\n",
      "  Using cached pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "Requirement already satisfied: torchmetrics in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-bolts) (0.11.4)\n",
      "Requirement already satisfied: lightning-utilities>0.3.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-bolts) (0.9.0)\n",
      "Requirement already satisfied: torchvision>=0.10.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-bolts) (0.15.2)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-bolts) (2.13.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-utilities>0.3.1->lightning-bolts) (23.1)\n",
      "Requirement already satisfied: typing-extensions in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-utilities>0.3.1->lightning-bolts) (4.5.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.0.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2023.6.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (1.56.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (3.4.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (4.23.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (59.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (2.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (0.40.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torchvision>=0.10.0->lightning-bolts) (9.5.0)\n",
      "Requirement already satisfied: filelock in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.12.2)\n",
      "Requirement already satisfied: sympy in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.12)\n",
      "Requirement already satisfied: networkx in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (16.0.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.8.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->lightning-bolts) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->lightning-bolts) (6.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->lightning-bolts) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->lightning-bolts) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->lightning-bolts) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->lightning-bolts) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->lightning-bolts) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->lightning-bolts) (3.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sympy->torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.3.0)\n",
      "Installing collected packages: pytorch-lightning\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.5.10\n",
      "    Uninstalling pytorch-lightning-1.5.10:\n",
      "      Successfully uninstalled pytorch-lightning-1.5.10\n",
      "Successfully installed pytorch-lightning-1.9.5\n",
      "Requirement already satisfied: torchmetrics in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (0.11.4)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torchmetrics) (1.22.4)\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torchmetrics) (2.0.1)\n",
      "Requirement already satisfied: packaging in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: filelock in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->torchmetrics) (59.5.0)\n",
      "Requirement already satisfied: wheel in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->torchmetrics) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install ipywidgets\n",
    "!pip install pytorch-lightning==1.5.10\n",
    "!pip install nvidia-ml-py3\n",
    "!pip install neptune-client\n",
    "!pip install lightning-bolts\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model, Wav2Vec2Config\n",
    "import torch\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import Wav2Vec2FeatureEncoder, Wav2Vec2NoLayerNormConvLayer, Wav2Vec2LayerNormConvLayer\n",
    "from torch import nn\n",
    "from transformers.activations import ACT2FN\n",
    "import ipywidgets\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import torchaudio\n",
    "import torchtext\n",
    "import pytorch_lightning as pl\n",
    "import nvidia_smi\n",
    "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from IPython.display import display, HTML\n",
    "from dataclasses import dataclass, field\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "from torchmetrics import Accuracy\n",
    "from torchmetrics import F1Score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import contextlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if the GPU is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  1 13:09:59 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000    Off  | 00000000:B3:00.0  On |                  Off |\n",
      "| 41%   44C    P8    22W / 140W |   2269MiB / 16376MiB |     43%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1930      G   /usr/lib/xorg/Xorg                 39MiB |\n",
      "|    0   N/A  N/A      3655      G   /usr/lib/xorg/Xorg                165MiB |\n",
      "|    0   N/A  N/A      3805      G   /usr/bin/gnome-shell               49MiB |\n",
      "|    0   N/A  N/A      4438      G   ...RendererForSitePerProcess      165MiB |\n",
      "|    0   N/A  N/A      6437      C   ...da3/envs/coEnv/bin/python     1624MiB |\n",
      "|    0   N/A  N/A      9047      G   /usr/lib/firefox/firefox          208MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Lightning Version: 1.9.5\n",
      "Device name: b'NVIDIA RTX A4000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pytorch Lightning Version: {pl.__version__}\")\n",
    "nvidia_smi.nvmlInit()\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "print(f\"Device name: {nvidia_smi.nvmlDeviceGetName(handle)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': 'wav2vec2-sound_sismic_train',\n",
       " 'lr': 1e-05,\n",
       " 'w_decay': 0,\n",
       " 'bs': 16,\n",
       " 'patience': 30,\n",
       " 'hold_epochs': 20,\n",
       " 'accum_grads': 4,\n",
       " 'pretrained': 'facebook/wav2vec2-base-960h',\n",
       " 'wav2vec2_processor': 'facebook/wav2vec2-base-960h',\n",
       " 'freeze_finetune_updates': 0,\n",
       " 'warmup_epochs': 40,\n",
       " 'apply_mask': False,\n",
       " 'mask_time_length': 10,\n",
       " 'max_epochs': 300}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version = \"wav2vec2-sound_sismic_train\" #@param {type: \"string\"}\n",
    "lr = 1e-5#@param {type: \"number\"}\n",
    "w_decay = 0#@param {type: \"number\"}\n",
    "bs = 16#@param {type: \"integer\"}\n",
    "accum_grads = 4#@param {type: \"integer\"}\n",
    "patience = 30#@param {type: \"integer\"}\n",
    "max_epochs = 300#@param {type: \"integer\"}\n",
    "# warmup_steps = 1000#@param {type: \"integer\"}\n",
    "hold_epochs = 20#@param {type: \"integer\"}\n",
    "pretrained = \"facebook/wav2vec2-base-960h\"#@param {type: \"string\"}\n",
    "wav2vec2_processor = \"facebook/wav2vec2-base-960h\"#@param {type: \"string\"}\n",
    "freeze_finetune_updates = 0#@param {type: \"integer\"}\n",
    "warmup_epochs = 40#@param {type: \"integer\"}\n",
    "apply_mask=False#@param {type: \"boolean\"}\n",
    "mask_time_length= 10#@param {type: \"integer\"}, era 1\n",
    "\n",
    "# Define hyperparameters\n",
    "hparams = {\"version\": version,\n",
    "          \"lr\": lr,\n",
    "          \"w_decay\": w_decay,\n",
    "          \"bs\": bs,\n",
    "          \"patience\": patience,\n",
    "          \"hold_epochs\":hold_epochs,\n",
    "          \"accum_grads\": accum_grads,\n",
    "          \"pretrained\":pretrained,\n",
    "          \"wav2vec2_processor\": wav2vec2_processor,\n",
    "          \"freeze_finetune_updates\":freeze_finetune_updates,\n",
    "          \"warmup_epochs\":warmup_epochs,\n",
    "          \"apply_mask\":apply_mask,\n",
    "          \"mask_time_length\":mask_time_length,\n",
    "          \"max_epochs\": max_epochs}\n",
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the original processor from Wav2Vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(hparams[\"wav2vec2_processor\"], return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav2Vec2Processor:\n",
      "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "- tokenizer: PreTrainedTokenizer(name_or_path='facebook/wav2vec2-base-960h', vocab_size=32, model_max_len=9223372036854775807, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'})\n"
     ]
    }
   ],
   "source": [
    "print(processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalize the model to accept n channels instead of just 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wav2Vec2GroupNormConvLayer(nn.Module):\n",
    "    def __init__(self, config, num_input_channels=1, layer_id=0):\n",
    "        super().__init__()\n",
    "        self.num_input_channels = num_input_channels\n",
    "        self.in_conv_dim = config.conv_dim[layer_id - 1] if layer_id > 0 else self.num_input_channels\n",
    "        self.out_conv_dim = config.conv_dim[layer_id]\n",
    "\n",
    "        self.conv = nn.Conv1d(\n",
    "            self.in_conv_dim,\n",
    "            self.out_conv_dim,\n",
    "            kernel_size=config.conv_kernel[layer_id],\n",
    "            stride=config.conv_stride[layer_id],\n",
    "            bias=config.conv_bias,\n",
    "        )\n",
    "        self.activation = ACT2FN[config.feat_extract_activation]\n",
    "\n",
    "        self.layer_norm = nn.GroupNorm(num_groups=self.out_conv_dim, num_channels=self.out_conv_dim, affine=True)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.conv(hidden_states)\n",
    "        hidden_states = self.layer_norm(hidden_states)\n",
    "        hidden_states = self.activation(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "class Wav2Vec2_ChannelFeatureEncoder(nn.Module):\n",
    "    \"\"\"Construct the features from raw audio waveform\"\"\"\n",
    "\n",
    "    def __init__(self, config, num_input_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_input_channels = num_input_channels\n",
    "        \n",
    "        if config.feat_extract_norm == \"group\":\n",
    "            conv_layers = [Wav2Vec2GroupNormConvLayer(config, num_input_channels= self.num_input_channels,layer_id=0)] + [\n",
    "                Wav2Vec2NoLayerNormConvLayer(config, layer_id=i + 1) for i in range(config.num_feat_extract_layers - 1)\n",
    "            ]\n",
    "        elif config.feat_extract_norm == \"layer\":\n",
    "            conv_layers = [\n",
    "                Wav2Vec2LayerNormConvLayer(config, layer_id=i) for i in range(config.num_feat_extract_layers)\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"`config.feat_extract_norm` is {config.feat_extract_norm}, but has to be one of ['group', 'layer']\"\n",
    "            )\n",
    "        self.conv_layers = nn.ModuleList(conv_layers)\n",
    "        self.gradient_checkpointing = False\n",
    "        self._requires_grad = True\n",
    "\n",
    "    def _freeze_parameters(self):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "        self._requires_grad = False\n",
    "\n",
    "    def forward(self, input_values):\n",
    "        hidden_states = input_values[:] # mudou para que receba todos os canais (4)\n",
    "        #print(\"hidden_states\", hidden_states.shape)\n",
    "\n",
    "        # make sure hidden_states require grad for gradient_checkpointing\n",
    "        if self._requires_grad and self.training:\n",
    "            hidden_states.requires_grad = True\n",
    "\n",
    "        for conv_layer in self.conv_layers:\n",
    "            if self._requires_grad and self.gradient_checkpointing and self.training:\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                hidden_states = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(conv_layer),\n",
    "                    hidden_states,\n",
    "                )\n",
    "            else:\n",
    "                hidden_states = conv_layer(hidden_states)\n",
    "\n",
    "        return hidden_states\n",
    "\n",
    "# Crio o novo modelo que herda os processos de Wav2Vec2, mas usa o extrator de features baseado em 4 canais\n",
    "class Wav2Vec2_ChannelModel(Wav2Vec2Model):\n",
    "    def __init__(self, config: Wav2Vec2Config, num_input_channels=1):\n",
    "        super().__init__(config)\n",
    "\n",
    "        #del self.feature_extractor\n",
    "        self.feature_extractor = Wav2Vec2_ChannelFeatureEncoder(config, num_input_channels=num_input_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2_ChannelModel: ['lm_head.bias', 'lm_head.weight', 'wav2vec2.feature_extractor.conv_layers.6.conv.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2_ChannelModel were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2_ChannelModel.from_pretrained(\"facebook/wav2vec2-base-960h\",\n",
    "                                                 conv_dim = (512, 512, 512,512,512,512),\n",
    "                                                 conv_stride = (5, 2, 2,2,2,2),\n",
    "                                                 conv_kernel = (10, 3, 3,3,3,2),\n",
    "                                                 num_feat_extract_layers = 6,\n",
    "                                                 num_input_channels = 1,\n",
    "                                                 ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav2Vec2_ChannelModel(\n",
      "  (feature_extractor): Wav2Vec2_ChannelFeatureEncoder(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Wav2Vec2GroupNormConvLayer(\n",
      "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (5): Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_projection): Wav2Vec2FeatureProjection(\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): Wav2Vec2Encoder(\n",
      "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "      (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
      "      (padding): Wav2Vec2SamePadLayer()\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO THE TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#import os\n",
    "#import shutil\n",
    "#import librosa\n",
    "\n",
    "# #Define la ruta de la carpeta que contiene los archivos de audio\n",
    "#input_folder = '/media/cslab03/TOSHIBA EXT/TESIS/DataSet/AudioSismig1/'\n",
    "\n",
    "# #Lista todos los archivos de la carpeta\n",
    "#files = [os.path.join(input_folder, file) for file in os.listdir(input_folder)]\n",
    "\n",
    "# #Define las proporciones para train, test y validation sets\n",
    "#train_ratio = 0.7\n",
    "#test_ratio = 0.15\n",
    "#validation_ratio = 0.15\n",
    "\n",
    "# ##Divide los datos en train, test y validation sets\n",
    "#train_files, temp_files = train_test_split(files, test_size=1 - train_ratio)\n",
    "#test_files, validation_files = train_test_split(temp_files, test_size=validation_ratio / (test_ratio + validation_ratio))\n",
    "\n",
    " #Define las carpetas de salida\n",
    "#output_folder = './data1/'\n",
    "#os.makedirs(os.path.join(output_folder, 'train'), exist_ok=True)\n",
    "#os.makedirs(os.path.join(output_folder, 'test'), exist_ok=True)\n",
    "#os.makedirs(os.path.join(output_folder, 'validation'), exist_ok=True)\n",
    "\n",
    "\n",
    " #Copia los archivos a las carpetas correspondientes\n",
    "#for file in train_files:\n",
    "#    if 'BHZ' in file:    \n",
    "#        try:\n",
    "#            audio, _ = librosa.load(file, sr=None)\n",
    "#            shutil.copy(file, os.path.join(output_folder, 'train'))\n",
    "#        except Exception as e:\n",
    "#            print(e)\n",
    "#            print(file)\n",
    "#    else:\n",
    "#        continue\n",
    "    \n",
    "#for file in test_files:\n",
    "#    if 'BHZ' in file:\n",
    "#        try:\n",
    "#            audio, _ = librosa.load(file, sr=None)\n",
    "#            shutil.copy(file, os.path.join(output_folder, 'test'))\n",
    "#        except Exception as e:\n",
    "#            print(e)\n",
    "#            print(file)\n",
    "#    else:\n",
    "#        continue\n",
    "    \n",
    "#for file in validation_files:\n",
    "#    if 'BHZ' in file:\n",
    "#        try:\n",
    "#            audio, _ = librosa.load(file, sr=None)\n",
    "#            shutil.copy(file, os.path.join(output_folder, 'validation'))\n",
    "#        except Exception as e:\n",
    "#            print(e)\n",
    "#            print(file)\n",
    "#    else:\n",
    "#        continue\n",
    "\n",
    "#print(\"Data split completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANSYN_Dataset_SE(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, filenames, audio_path):\n",
    "        self.filenames = [filename for filename in filenames if not any(substring in filename for substring in ['TRBA', 'EXPL', 'VLP', 'TRESP'])]\n",
    "        self.audio_path = audio_path\n",
    "    \n",
    "    def process_audio(self, signal, new_sr):\n",
    "        # right pad if necessary\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < 17787:\n",
    "            num_missing_samples = 17787 - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        elif length_signal > 17787:\n",
    "            signal = signal[:, :17787]\n",
    "            \n",
    "        return signal\n",
    "    \n",
    "\n",
    "    def normalize_layer(self, feats):\n",
    "        with torch.no_grad():\n",
    "            feats = torch.nn.functional.layer_norm(feats, feats.shape)\n",
    "        return feats\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Intenta cargar el archivo de audio\n",
    "        feats, _ = torchaudio.load(self.audio_path + self.filenames[index])\n",
    "\n",
    "\n",
    "        # Asigna una etiqueta de destino basada en el nombre del archivo\n",
    "        if 'HB' in self.filenames[index]:\n",
    "            target = torch.tensor(int('00')).long() \n",
    "        elif 'LP' in self.filenames[index]:\n",
    "            target = torch.tensor(int('01')).long()\n",
    "        elif 'VT' in self.filenames[index]:\n",
    "            target = torch.tensor(int('02')).long()\n",
    "            \n",
    "        feats = self.process_audio(feats, 16000)\n",
    "        feats = self.normalize_layer(feats)\n",
    "        \n",
    "        return {\"input_values\": feats, \"target\": target}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = os.listdir('/home/cslab03/Desktop/QuakeWavNet/data1/train/')\n",
    "X_test = os.listdir('/home/cslab03/Desktop/QuakeWavNet/data1/test/')\n",
    "X_val = os.listdir('/home/cslab03/Desktop/QuakeWavNet/data1/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0fc78c1240fd3534f433cce8d3a5fdd_BHZ_BNAS_LP.wav\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ANSYN_Dataset_SE(X_train, '/home/cslab03/Desktop/QuakeWavNet/data1/train/')\n",
    "val_dataset =  ANSYN_Dataset_SE(X_val, '/home/cslab03/Desktop/QuakeWavNet/data1/validation/')\n",
    "test_dataset = ANSYN_Dataset_SE(X_test, '/home/cslab03/Desktop/QuakeWavNet/data1/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[-0.3224, -0.2470, -0.2385,  ...,  2.0274,  2.0274,  2.0274]]),\n",
       " 'target': tensor(1)}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras de treinamento: 14612\n",
      "Número de amostras de validação: 3178\n",
      "Número de amostras de teste: 3232\n"
     ]
    }
   ],
   "source": [
    "print('Número de amostras de treinamento:', len(train_dataset))\n",
    "print('Número de amostras de validação:', len(val_dataset))\n",
    "print('Número de amostras de teste:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      "{'LP': 8369, 'VT': 5837, 'HB': 406}\n"
     ]
    }
   ],
   "source": [
    "label_distribution = {}\n",
    "for data in train_dataset:\n",
    "    label = data[\"target\"].item()\n",
    "    \n",
    "    if label == 0:\n",
    "        label = \"HB\"\n",
    "    elif label == 1:\n",
    "        label = \"LP\"\n",
    "    elif label == 2:\n",
    "        label = \"VT\"\n",
    "        \n",
    "    if label in label_distribution:\n",
    "        label_distribution[label] += 1\n",
    "    else:\n",
    "        label_distribution[label] = 1\n",
    "\n",
    "    \n",
    "print(\"Label distribution:\")\n",
    "print(label_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequência de amostragem aceita pelo modelo: 16000\n",
      "Input values dimensão: torch.Size([1, 1, 17787])\n",
      "{'input_values': tensor([[[-0.0519, -0.0224, -0.0146,  ...,  0.6665,  0.6665,  0.6665]]]), 'attention_mask': tensor([[1]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "target_sampling_rate = processor.feature_extractor.sampling_rate\n",
    "print(f\"Frequência de amostragem aceita pelo modelo: {target_sampling_rate}\")\n",
    "# Conferindo se os dados de entrada não geram erro no processor\n",
    "inputs = processor(train_dataset[5][\"input_values\"], sampling_rate=target_sampling_rate, return_tensors=\"pt\")\n",
    "print(f'Input values dimensão: {inputs[\"input_values\"].shape}')\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensões de entrada do modelo:\n",
      "Dimensões de saída do modelo: \n",
      " torch.Size([1, 110, 768])\n"
     ]
    }
   ],
   "source": [
    "print('Dimensões de entrada do modelo:')\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "print('Dimensões de saída do modelo: \\n',last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorWithPadding:\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "@dataclass\n",
    "class DataCollatorWithPadding:\n",
    "     \"\"\"\n",
    "     Data collator that will dynamically pad the inputs received.\n",
    "     Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "             The processor used for proccessing the data.\n",
    "         padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "             Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "             among:\n",
    "             * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "               sequence if provided).\n",
    "             * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "               maximum acceptable input length for the model if that argument is not provided.\n",
    "             * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "               different lengths).\n",
    "         max_length (:obj:`int`, `optional`):\n",
    "             Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "         max_length_labels (:obj:`int`, `optional`):\n",
    "             Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "         pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "             If set will pad the sequence to a multiple of the provided value.\n",
    "             This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "             7.5 (Volta).\n",
    "     \"\"\"\n",
    "     processor: Wav2Vec2Processor\n",
    "     padding: Union[bool, str] = True\n",
    "     max_length: Optional[int] = None\n",
    "     max_length_labels: Optional[int] = None\n",
    "     pad_to_multiple_of: Optional[int] = None\n",
    "     pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "     def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "                \n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"target\"]} for feature in features]\n",
    "        batch = self.processor.pad(\n",
    "             input_features,\n",
    "             padding=self.padding,\n",
    "             max_length=self.max_length,\n",
    "             pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "             return_tensors=\"pt\",\n",
    "         )\n",
    "        #print('batch', batch)\n",
    "        with self.processor.as_target_processor(): labels_batch = self.processor.pad( label_features, padding=True,max_length=self.max_length_labels,pad_to_multiple_of=self.pad_to_multiple_of_labels,return_tensors=\"pt\",)\n",
    "        #print('labels_batch', labels_batch)\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"]\n",
    "\n",
    "        batch[\"target\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(processor=processor,\n",
    "                                        #max_length=188,\n",
    "                                        padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de minibatches de treinamento: 914\n",
      "Número de minibatches de validação: 199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dimensões dos dados de um minibatch - Audio: torch.Size([16, 1, 17787])\n",
      "\n",
      "Dimensões dos dados de um minibatch - Target: torch.Size([16])\n",
      "Valores mínimo e máximo entrada:  tensor(-13.9080) tensor(11.4029)\n",
      "Valores mínimo e máximo saída:  tensor(1) tensor(2)\n",
      "Tipo dos dados dos áudios:          <class 'torch.Tensor'>\n",
      "Tipo das classes das classes:        <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "batch_size = hparams[\"bs\"]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              collate_fn = data_collator,\n",
    "                              shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                            collate_fn = data_collator,\n",
    "                            shuffle=False, num_workers=4)\n",
    "\n",
    "print('Número de minibatches de treinamento:', len(train_dataloader))\n",
    "print('Número de minibatches de validação:', len(val_dataloader))\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "#print(batch)\n",
    "\n",
    "x_train, y_train = batch['input_values'], batch['target']\n",
    "print(\"\\nDimensões dos dados de um minibatch - Audio:\", x_train.size())\n",
    "# print(\"\\nDimensões dos dados de um minibatch:\", padding_mask.size())\n",
    "print(\"\\nDimensões dos dados de um minibatch - Target:\", y_train.size())\n",
    "print(\"Valores mínimo e máximo entrada: \", torch.min(x_train), torch.max(x_train))\n",
    "print(\"Valores mínimo e máximo saída: \", torch.min(y_train), torch.max(y_train))\n",
    "print(\"Tipo dos dados dos áudios:         \", type(x_train))\n",
    "print(\"Tipo das classes das classes:       \", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[[-0.5511, -0.6016, -0.6138,  ...,  0.4212,  0.4212,  0.4212]],\n",
       "\n",
       "        [[ 0.2266,  0.3420,  0.3184,  ...,  0.2867,  0.2867,  0.2867]],\n",
       "\n",
       "        [[ 0.3450,  0.2662,  0.2874,  ...,  1.0237,  1.0237,  1.0237]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.1336,  0.1017,  0.1144,  ...,  0.0527,  0.0527,  0.0527]],\n",
       "\n",
       "        [[ 0.0865, -0.5453, -1.2054,  ...,  0.5155,  0.5155,  0.5155]],\n",
       "\n",
       "        [[ 0.9739,  1.1446,  1.1632,  ..., -1.4997, -1.4997, -1.4997]]]), 'attention_mask': tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=torch.int32), 'target': tensor([1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2])}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': tensor([[[ 0.3522,  0.2914,  0.2553,  ...,  1.4601,  1.4601,  1.4601]],\n",
       "\n",
       "        [[-1.0479, -1.2072, -1.2587,  ...,  2.1877,  2.1877,  2.1877]],\n",
       "\n",
       "        [[-0.2843, -0.2493, -0.2657,  ..., -0.9526, -0.9526, -0.9526]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.0224,  0.1868,  0.2293,  ...,  0.0398,  0.0398,  0.0398]],\n",
       "\n",
       "        [[-0.2172, -0.1936, -0.1805,  ...,  2.9597,  2.9597,  2.9597]],\n",
       "\n",
       "        [[-0.4067, -0.4369, -0.4470,  ...,  1.8822,  1.8822,  1.8822]]]), 'attention_mask': tensor([[1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], dtype=torch.int32), 'target': tensor([2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2])}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "f1 = F1Score(num_classes=n_classes, average='macro', task='multiclass')\n",
    "accuracy = Accuracy(num_classes=n_classes,task='multiclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = TensorBoardLogger(\"logs\", name=\"my_experiment_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wav2Vec2_sound_detection(pl.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hparams.update(hparams)\n",
    "\n",
    "        self.freeze_finetune_updates = hparams[\"freeze_finetune_updates\"]\n",
    "                \n",
    "        self.train_losses = [] \n",
    "        self.val_losses = []\n",
    "        self.val_f1_scores = []\n",
    "        self.test_f1_scores = []\n",
    "        self.confussion_matrix = None\n",
    "        \n",
    "        self.model = Wav2Vec2_ChannelModel.from_pretrained(hparams[\"pretrained\"],\n",
    "                                                 conv_dim = (512, 512, 512, 512, 512, 512),\n",
    "                                                 conv_stride = (5, 2, 2, 2, 2, 2),\n",
    "                                                 conv_kernel = (10, 3, 3, 3, 3, 2),\n",
    "                                                 num_feat_extract_layers = 6,\n",
    "                                                 apply_spec_augment=hparams[\"apply_mask\"],\n",
    "                                                 #mask_time_length=hparams[\"mask_time_length\"],\n",
    "                                                 num_input_channels = 1,\n",
    "                                                 ignore_mismatched_sizes=True)\n",
    "\n",
    "\n",
    "        # self.model.feature_extractor._freeze_parameters()\n",
    "\n",
    "        # freeze base-model\n",
    "        # for param in self.model.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.projector = nn.Linear(self.model.config.hidden_size, self.model.config.classifier_proj_size)\n",
    "        n_classes = 3\n",
    "        self.final_layer = nn.Linear(self.model.config.classifier_proj_size, n_classes)\n",
    "        self.logger_initialized = False\n",
    "    \n",
    "    def initialize_logger(self, logger):\n",
    "        self.logger = logger\n",
    "        self.logger_initialized = True\n",
    "\n",
    "    def forward(self, samples):\n",
    "                \n",
    "        \n",
    "        ft = self.freeze_finetune_updates <= self.trainer.global_step\n",
    "\n",
    "        with torch.no_grad() if not ft else contextlib.ExitStack():\n",
    "            hidden_states = self.model(**samples).last_hidden_state\n",
    "\n",
    "        padding_mask = self.model._get_feature_vector_attention_mask(hidden_states.shape[1], samples[\"attention_mask\"])\n",
    "\n",
    "        hidden_states[~padding_mask] = 0.0\n",
    "\n",
    "        pooled_output = hidden_states.sum(dim=1) / padding_mask.sum(dim=1).view(-1, 1)\n",
    "\n",
    "        proj_pooled = self.projector(pooled_output)\n",
    "\n",
    "        preds = self.final_layer(proj_pooled)\n",
    "\n",
    "        return F.log_softmax(preds, dim=1)\n",
    "\n",
    "    def _get_feature_vector_attention_mask(self, feature_vector_length: int, attention_mask: torch.LongTensor):\n",
    "        output_lengths = self._get_feat_extract_output_lengths(attention_mask.sum(-1)).to(torch.long)\n",
    "        batch_size = attention_mask.shape[0]\n",
    "\n",
    "        attention_mask = torch.zeros(\n",
    "            (batch_size, feature_vector_length), dtype=attention_mask.dtype, device=attention_mask.device\n",
    "        )\n",
    "\n",
    "        attention_mask[(torch.arange(attention_mask.shape[0], device=attention_mask.device), output_lengths - 1)] = 1\n",
    "        attention_mask = attention_mask.flip([-1]).cumsum(-1).flip([-1]).bool()\n",
    "        return attention_mask\n",
    "        \n",
    "        \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "\n",
    "        y_value = train_batch.pop(\"target\")\n",
    "        log_softs = self.forward(train_batch)\n",
    "    \n",
    "\n",
    "        loss = F.nll_loss(log_softs, y_value)\n",
    "\n",
    "        self.log('loss_step', loss, on_step=True, prog_bar=True)\n",
    "        \n",
    "        \n",
    "        #self.logger.log_metrics({'train_loss': loss.item()}, step=self.global_step)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        \n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.train_losses.append(loss.item())\n",
    "        \n",
    "        self.logger.log_metrics({'train_loss_epoch': loss.item()}, step=self.current_epoch)\n",
    "        \n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "\n",
    "        y_value = val_batch.pop(\"target\")\n",
    "\n",
    "        log_softs = self.forward(val_batch)\n",
    "        preds = torch.argmax(log_softs, dim=1)\n",
    "\n",
    "        val_acc = accuracy(preds.cpu(), y_value.cpu())\n",
    "        val_f1 = f1(preds.cpu(), y_value.cpu())\n",
    "        val_loss = F.nll_loss(log_softs, y_value)\n",
    "\n",
    "        self.log('val_acc', val_acc, prog_bar=True)\n",
    "        self.log('val_f1', val_f1, prog_bar=True)\n",
    "        self.log('val_loss', val_loss, prog_bar=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #self.logger.log_metrics({'val_acc': val_acc, 'val_f1': val_f1, 'val_loss': val_loss.item()}, step=self.global_step)\n",
    "\n",
    "        return {\"val_acc_step\": val_acc, \"val_f1_step\": val_f1, \"val_loss_step\": val_loss}\n",
    "\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        acc_mean = torch.stack([x['val_acc_step'] for x in outputs]).mean()\n",
    "        f1_mean = torch.stack([x['val_f1_step'] for x in outputs]).mean()\n",
    "        loss_mean = torch.stack([x['val_loss_step'] for x in outputs]).mean()\n",
    "                \n",
    "\n",
    "        self.log(\"val_acc\", acc_mean, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1_mean, prog_bar=True)\n",
    "        self.log(\"val_loss\", loss_mean, prog_bar=True)\n",
    "\n",
    "        self.val_f1_scores.append(f1_mean)\n",
    "        self.val_losses.append(loss_mean.item())\n",
    "        \n",
    "        self.logger.log_metrics({'val_acc_epoch': acc_mean, 'val_f1_epoch': f1_mean, 'val_loss_epoch': loss_mean.item()}, step=self.current_epoch)\n",
    "        \n",
    "    #import torch.functional as F\n",
    "    \n",
    "    \"\"\"def validation_epoch_end(self, outputs):\n",
    "        acc_mean = torch.stack([x['val_acc_step'] for x in outputs]).mean()\n",
    "        f1_mean = torch.stack([x['val_f1_step'] for x in outputs]).mean()\n",
    "        loss_mean = torch.stack([x['val_loss_step'] for x in outputs]).mean()\n",
    "\n",
    "        self.log(\"val_acc\", acc_mean, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1_mean, prog_bar=True)\n",
    "        self.log(\"val_loss\", loss_mean, prog_bar=True)\"\"\"\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "\n",
    "        y_value = test_batch.pop(\"target\")\n",
    "\n",
    "        log_softs = self.forward(test_batch)\n",
    "        preds = torch.argmax(log_softs, dim=1)\n",
    "\n",
    "        test_acc = accuracy(preds.cpu(), y_value.cpu())\n",
    "        test_f1 = f1(preds.cpu(), y_value.cpu())\n",
    "        test_loss = F.nll_loss(log_softs, y_value)\n",
    "\n",
    "        self.log('test_acc', test_acc, prog_bar=True)\n",
    "        self.log('test_f1', test_f1, prog_bar=True)\n",
    "        self.log('test_loss', test_loss, prog_bar=True)\n",
    "        \n",
    "        #self.logger.log_metrics({'test_acc': test_acc, 'test_f1': test_f1, 'test_loss': test_loss.item()}, step=self.global_step)\n",
    "        \n",
    "        return {\"test_acc_step\": test_acc, \"test_f1_step\": test_f1,  \"test_loss_step\": test_loss, \"preds\": preds, \"y_value\": y_value}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        acc_mean = torch.stack([x['test_acc_step'] for x in outputs]).mean()\n",
    "        f1_mean = torch.stack([x['test_f1_step'] for x in outputs]).mean()\n",
    "        loss_mean = torch.stack([x['test_loss_step'] for x in outputs]).mean()\n",
    "        \n",
    "\n",
    "        self.log(\"test_acc\", acc_mean, prog_bar=True)\n",
    "        self.log(\"test_f1\", f1_mean, prog_bar=True)\n",
    "        self.log(\"test_loss\", loss_mean, prog_bar=True)\n",
    "        \n",
    "        self.test_f1_scores.append(f1_mean)\n",
    "        all_preds = torch.cat([x['preds'] for x in outputs])\n",
    "        all_targets = torch.cat([x['y_value'] for x in outputs])\n",
    "        confusion = confusion_matrix(all_targets.cpu(), all_preds.cpu())\n",
    "        confusion_list = confusion_matrix.tolist()\n",
    "\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(confusion)\n",
    "        \n",
    "        self.logger.log_metrics({'test_acc_epoch': acc_mean, 'test_f1_epoch': f1_mean, 'test_loss_epoch': loss_mean.item(), 'Confusion Matrix': confusion_list}, step=self.current_epoch)\n",
    "        return {'Confusion Matrix': confusion_list}\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                         lr=self.hparams[\"lr\"],\n",
    "                         betas=(0.9,0.98),\n",
    "                         eps=1e-6,\n",
    "                         weight_decay=self.hparams[\"w_decay\"])\n",
    "\n",
    "        scheduler = LinearWarmupCosineAnnealingLR(optimizer,\n",
    "                                                  eta_min=0,\n",
    "                                                  warmup_start_lr=self.hparams[\"lr\"],\n",
    "                                                  warmup_epochs=self.hparams[\"warmup_epochs\"],\n",
    "                                                  max_epochs=self.hparams[\"max_epochs\"])\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjMWEyNTJlZS05ZDI5LTQzZjktYTkzNy00MDczMmZhODU3OWUifQ==\",\n",
    "    project='kgrosero/IA025-Project-wav2vec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Wav2Vec2_sound_detection(hparams)\n",
    "\n",
    "#trainer = pl.Trainer(gpus=1,\n",
    "#                     logger=neptune_logger,\n",
    " #                    max_epochs=100,\n",
    "  #                  overfit_batches=3,\n",
    "   #                 log_every_n_steps = 1)\n",
    "\n",
    "#trainer.fit(model, train_dataloader, val_dataloader)\n",
    "#del model, trainer # Para não ter estouro de mémoria da GPU\n",
    "#gc.collect()\n",
    "#torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2_ChannelModel: ['lm_head.bias', 'lm_head.weight', 'wav2vec2.feature_extractor.conv_layers.6.conv.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2_ChannelModel were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in /home/cslab03/Desktop/QuakeWavNet/Results/: ['wav2vec2-sound_sismic_train']\n",
      "Saving checkpoints to /home/cslab03/Desktop/QuakeWavNet/Results/\n"
     ]
    }
   ],
   "source": [
    "pl_model= Wav2Vec2_sound_detection(hparams=hparams, logger = logger)\n",
    "checkpoint_path = '/home/cslab03/Desktop/QuakeWavNet/Results/'\n",
    "checkpoint_dir = os.path.dirname(os.path.abspath(checkpoint_path))\n",
    "print(f'Files in {checkpoint_path}: {os.listdir(checkpoint_path)}')\n",
    "print(f'Saving checkpoints to {checkpoint_path}')\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(filename=hparams[\"version\"],\n",
    "                                                  dirpath=checkpoint_dir,\n",
    "                                                  save_top_k=1,\n",
    "                                                  verbose = True,\n",
    "                                                  monitor=\"val_f1\", mode=\"max\")\n",
    "early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_f1\", patience=hparams[\"patience\"], mode='max')\n",
    "early_stop_callback_1 = pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, mode='max')\n",
    "callbacks_list = [early_stop_callback]\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1,\n",
    "                     precision=16,\n",
    "                     logger=logger,\n",
    "                     num_sanity_val_steps=0,\n",
    "                     accumulate_grad_batches=hparams[\"accum_grads\"],\n",
    "                     enable_checkpointing=True,\n",
    "                     callbacks=callbacks_list + [lr_monitor, checkpoint_callback],\n",
    "                     max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/tmp/ipykernel_6437/2502373031.py:196: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  scheduler = LinearWarmupCosineAnnealingLR(optimizer,\n",
      "\n",
      "  | Name        | Type                  | Params\n",
      "------------------------------------------------------\n",
      "0 | model       | Wav2Vec2_ChannelModel | 93.8 M\n",
      "1 | projector   | Linear                | 196 K \n",
      "2 | final_layer | Linear                | 771   \n",
      "------------------------------------------------------\n",
      "94.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "94.0 M    Total params\n",
      "188.090   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3670b8ed56643b7af6b1537ae648051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318438f3bc1b41fdbe0928e4f2537c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 229: 'val_f1' reached 0.58693 (best 0.58693), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee91aa5f4f4a40a189cba5527c64ee62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 458: 'val_f1' reached 0.59159 (best 0.59159), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eabcff7342047c59aca881cb4d12c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 687: 'val_f1' reached 0.59207 (best 0.59207), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f24686bec6445bbd3db34d7bbda9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 916: 'val_f1' reached 0.59513 (best 0.59513), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f8659d78bf41c28b3e939c50d98c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 1145: 'val_f1' reached 0.59700 (best 0.59700), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ab1f81530c45e5ab7f95303039f9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 1374: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00542514a8f642feb0f256255c16edfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 1603: 'val_f1' reached 0.59848 (best 0.59848), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7bd6dcd69f14efeb223cc9bc25a48fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 1832: 'val_f1' reached 0.61028 (best 0.61028), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5d6372a0a04e1ca29126fef9e71c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 2061: 'val_f1' reached 0.61806 (best 0.61806), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf72fd686ad543b29d05c4359572dc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 2290: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149e2835dcb04c72bf0fe25a72e8d468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 2519: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d1458fd149406bb04871c06d4835d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 2748: 'val_f1' reached 0.61954 (best 0.61954), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a743699f049447d8b6a4033a13dd364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 2977: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cc94671f18406981334c302583f274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 3206: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e16e2696b64916a5113b4c7ef4d3a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 3435: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde06c215b8c4be98515d86b0570d781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 3664: 'val_f1' reached 0.62268 (best 0.62268), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4c6e341da84d2aa66c79c8478b9370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 3893: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a407f302c8d41aba63473ec4bb04b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 4122: 'val_f1' reached 0.62834 (best 0.62834), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115d1a746b5c45d8aca732be3bb62c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 4351: 'val_f1' reached 0.63092 (best 0.63092), saving model to '/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt' as top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d776c299864ae5b1d238197dce897b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 4580: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0bd69ac7a9a40b0abbace254cccd6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 4809: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8dbb2cc9ce0476d89f950f7bc5d15d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 5038: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369a709c51f74b37b132dd445ffdf764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 5267: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771110af4f5a4ceab17e3b0988b84753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 5496: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4cb7a4de67d4974a3d521aacbe8ad5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 5725: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a857bf48f788401ab52b61ca2790f0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25, global step 5954: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d81394bc5ba49dda188ef1c941cca63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26, global step 6183: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fecfffeffab4ccd8c8e4736ade8736b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27, global step 6412: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d507ea1366845448bd4819d65bb2000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28, global step 6641: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3884a1facf04bb4bd02fde89bfc952f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29, global step 6870: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe33da191fe424e99626bb81622237e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30, global step 7099: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c1a4ac437640eaa696168114501403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31, global step 7328: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b37dcc88e14b3ab96fb4d78ce55a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32, global step 7557: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e27662dbf494b4fa1a69430dd321368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33, global step 7786: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7695a93f82942f78e4cb735b712412d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34, global step 8015: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc910975f9e41b2b09832cec2f84260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35, global step 8244: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b725a8789882470e856851dc096ca670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36, global step 8473: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9ce776d6a54fa1b117cde190487b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37, global step 8702: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6a126cbd134553ad309b5629607075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38, global step 8931: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74c59d5277024c54942d5075e01c8298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39, global step 9160: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d80a8a43e2944ba818125be57288f0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40, global step 9389: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a88673d87434f60931d057464e35342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41, global step 9618: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070d860ae8694ed18c88e47f282bb4e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42, global step 9847: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93685eeef2dc4f578d5ae425e440b2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43, global step 10076: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8b8934728d4939b8c9ed24d75a751e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44, global step 10305: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dd0a31c10e42caab1fa525e00fc47a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45, global step 10534: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3b78dc5ad44109a106e7d723f6b1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46, global step 10763: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfd33bf065642f3a709dc5995e01cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47, global step 10992: 'val_f1' was not in top 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d7d41a499a4a498a6b044195a8fca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48, global step 11221: 'val_f1' was not in top 1\n"
     ]
    }
   ],
   "source": [
    "# Definir listas para almacenar las métricas por época\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_f1_scores = []\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer.fit(pl_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processor to: /home/cslab03/Desktop/QuakeWavNet/Results/wav2vec2-sound_sismic_train\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(checkpoint_path + hparams[\"version\"]):\n",
    "    print('Saving processor to: ' + checkpoint_path + hparams[\"version\"])\n",
    "    processor.save_pretrained(checkpoint_path + hparams[\"version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "checkpoint_callback.best_model_path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Después de completar el entrenamiento\n",
    "epochs = list(range(1, len(pl_model.val_f1_scores) + 1))\n",
    "plt.plot(epochs, pl_model.val_f1_scores, marker='o')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('F1-score por Época')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cslab03/Desktop/QuakeWavNet/wav2vec2-sound_sismic_train-v7.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2_ChannelModel: ['lm_head.bias', 'lm_head.weight', 'wav2vec2.feature_extractor.conv_layers.6.conv.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2_ChannelModel were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "best_model = checkpoint_callback.best_model_path\n",
    "# best_model = \"/content/drive/MyDrive/Wav2Vec2_ORVP/wav2vec2_huggingface_fairseq_orvp_test1-epoch=4-step=23459.ckpt\"\n",
    "print(best_model)\n",
    "test_model = Wav2Vec2_sound_detection.load_from_checkpoint(best_model, hparams=hparams).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4830ceaf8095480da045faf0109cdc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  19   21   35]\n",
      " [  16 1727  131]\n",
      " [  13   87 1129]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n you tried to log [[  19   21   35]\n [  16 1727  131]\n [  13   87 1129]] which is currently not supported. Try a dict or a scalar/tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/lightning_fabric/loggers/tensorboard.py:202\u001b[0m, in \u001b[0;36mTensorBoardLogger.log_metrics\u001b[0;34m(self, metrics, step)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment\u001b[39m.\u001b[39;49madd_scalar(k, v, step)\n\u001b[1;32m    203\u001b[0m \u001b[39m# TODO(fabric): specify the possible exception\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py:388\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[1;32m    386\u001b[0m     scalar_value \u001b[39m=\u001b[39m workspace\u001b[39m.\u001b[39mFetchBlob(scalar_value)\n\u001b[0;32m--> 388\u001b[0m summary \u001b[39m=\u001b[39m scalar(\n\u001b[1;32m    389\u001b[0m     tag, scalar_value, new_style\u001b[39m=\u001b[39;49mnew_style, double_precision\u001b[39m=\u001b[39;49mdouble_precision\n\u001b[1;32m    390\u001b[0m )\n\u001b[1;32m    391\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_file_writer()\u001b[39m.\u001b[39madd_summary(summary, global_step, walltime)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/tensorboard/summary.py:281\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, tensor, collections, new_style, double_precision)\u001b[0m\n\u001b[1;32m    280\u001b[0m tensor \u001b[39m=\u001b[39m make_np(tensor)\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m--> 281\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[1;32m    282\u001b[0m     tensor\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    283\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTensor should contain one element (0 dimensions). Was given size: \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39msize\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m \u001b[39m# python float is double precision in numpy\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor should contain one element (0 dimensions). Was given size: 9 and 2 dimensions.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X60sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtest(test_model, val_dataloader)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:794\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    792\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    793\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 794\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    795\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[1;32m    796\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:842\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tested_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path  \u001b[39m# TODO: remove in v1.8\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[39m# run test\u001b[39;00m\n\u001b[0;32m--> 842\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    844\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtesting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1112\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1114\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1188\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mdispatch(\u001b[39mself\u001b[39m)\n\u001b[1;32m   1187\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluating:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_evaluate()\n\u001b[1;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1228\u001b[0m, in \u001b[0;36mTrainer._run_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   1225\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrun_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstage\u001b[39m}\u001b[39;00m\u001b[39m_evaluation\u001b[39m\u001b[39m\"\u001b[39m), _evaluation_context(\n\u001b[1;32m   1226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_mode\n\u001b[1;32m   1227\u001b[0m ):\n\u001b[0;32m-> 1228\u001b[0m     eval_loop_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1230\u001b[0m \u001b[39m# remove the tensors from the eval results\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m eval_loop_results:\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:206\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_run_end()\n\u001b[1;32m    207\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:180\u001b[0m, in \u001b[0;36mEvaluationLoop.on_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39mepoch_end_reached()\n\u001b[1;32m    179\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_epoch_end(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_outputs)\n\u001b[1;32m    181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m []  \u001b[39m# free memory\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m# hook\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:288\u001b[0m, in \u001b[0;36mEvaluationLoop._evaluation_epoch_end\u001b[0;34m(self, outputs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39m# call the model epoch end\u001b[39;00m\n\u001b[1;32m    287\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_epoch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_epoch_end\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 288\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_lightning_module_hook(hook_name, output_or_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1356\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m   1355\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1356\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1358\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "\u001b[1;32m/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb Cell 43\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X60sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X60sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m \u001b[39mprint\u001b[39m(confusion)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X60sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger\u001b[39m.\u001b[39;49mlog_metrics({\u001b[39m'\u001b[39;49m\u001b[39mtest_acc_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m: acc_mean, \u001b[39m'\u001b[39;49m\u001b[39mtest_f1_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m: f1_mean, \u001b[39m'\u001b[39;49m\u001b[39mtest_loss_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m: loss_mean\u001b[39m.\u001b[39;49mitem(), \u001b[39m'\u001b[39;49m\u001b[39mConfusion Matrix\u001b[39;49m\u001b[39m'\u001b[39;49m: confusion}, step\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_epoch)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X60sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mConfusion Matrix\u001b[39m\u001b[39m'\u001b[39m: confusion}\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/lightning_utilities/core/rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/lightning_fabric/loggers/tensorboard.py:206\u001b[0m, in \u001b[0;36mTensorBoardLogger.log_metrics\u001b[0;34m(self, metrics, step)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m    205\u001b[0m     m \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m you tried to log \u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m}\u001b[39;00m\u001b[39m which is currently not supported. Try a dict or a scalar/tensor.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(m) \u001b[39mfrom\u001b[39;00m \u001b[39mex\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: \n you tried to log [[  19   21   35]\n [  16 1727  131]\n [  13   87 1129]] which is currently not supported. Try a dict or a scalar/tensor."
     ]
    }
   ],
   "source": [
    "trainer.test(test_model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                            collate_fn = data_collator,\n",
    "                            shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7504a95f3ae34f2ba42d7aa4f2264688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  14   32   36]\n",
      " [  15 1687  112]\n",
      " [  11   85 1240]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\n you tried to log [[  14   32   36]\n [  15 1687  112]\n [  11   85 1240]] which is currently not supported. Try a dict or a scalar/tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/lightning_fabric/loggers/tensorboard.py:202\u001b[0m, in \u001b[0;36mTensorBoardLogger.log_metrics\u001b[0;34m(self, metrics, step)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment\u001b[39m.\u001b[39;49madd_scalar(k, v, step)\n\u001b[1;32m    203\u001b[0m \u001b[39m# TODO(fabric): specify the possible exception\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/tensorboard/writer.py:388\u001b[0m, in \u001b[0;36mSummaryWriter.add_scalar\u001b[0;34m(self, tag, scalar_value, global_step, walltime, new_style, double_precision)\u001b[0m\n\u001b[1;32m    386\u001b[0m     scalar_value \u001b[39m=\u001b[39m workspace\u001b[39m.\u001b[39mFetchBlob(scalar_value)\n\u001b[0;32m--> 388\u001b[0m summary \u001b[39m=\u001b[39m scalar(\n\u001b[1;32m    389\u001b[0m     tag, scalar_value, new_style\u001b[39m=\u001b[39;49mnew_style, double_precision\u001b[39m=\u001b[39;49mdouble_precision\n\u001b[1;32m    390\u001b[0m )\n\u001b[1;32m    391\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_file_writer()\u001b[39m.\u001b[39madd_summary(summary, global_step, walltime)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/tensorboard/summary.py:281\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, tensor, collections, new_style, double_precision)\u001b[0m\n\u001b[1;32m    280\u001b[0m tensor \u001b[39m=\u001b[39m make_np(tensor)\u001b[39m.\u001b[39msqueeze()\n\u001b[0;32m--> 281\u001b[0m \u001b[39massert\u001b[39;00m (\n\u001b[1;32m    282\u001b[0m     tensor\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    283\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTensor should contain one element (0 dimensions). Was given size: \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39msize\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{\u001b[39;00mtensor\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m dimensions.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m \u001b[39m# python float is double precision in numpy\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tensor should contain one element (0 dimensions). Was given size: 9 and 2 dimensions.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb Cell 45\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtest(test_model, test_dataloader)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:794\u001b[0m, in \u001b[0;36mTrainer.test\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    792\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    793\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 794\u001b[0m \u001b[39mreturn\u001b[39;00m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    795\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_test_impl, model, dataloaders, ckpt_path, verbose, datamodule\n\u001b[1;32m    796\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:842\u001b[0m, in \u001b[0;36mTrainer._test_impl\u001b[0;34m(self, model, dataloaders, ckpt_path, verbose, datamodule)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tested_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path  \u001b[39m# TODO: remove in v1.8\u001b[39;00m\n\u001b[1;32m    841\u001b[0m \u001b[39m# run test\u001b[39;00m\n\u001b[0;32m--> 842\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    844\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtesting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1112\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1114\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1188\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mdispatch(\u001b[39mself\u001b[39m)\n\u001b[1;32m   1187\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluating:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_evaluate()\n\u001b[1;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1228\u001b[0m, in \u001b[0;36mTrainer._run_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1223\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluation_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   1225\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrun_\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstage\u001b[39m}\u001b[39;00m\u001b[39m_evaluation\u001b[39m\u001b[39m\"\u001b[39m), _evaluation_context(\n\u001b[1;32m   1226\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inference_mode\n\u001b[1;32m   1227\u001b[0m ):\n\u001b[0;32m-> 1228\u001b[0m     eval_loop_results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_loop\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m   1230\u001b[0m \u001b[39m# remove the tensors from the eval results\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m eval_loop_results:\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:206\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mon_run_end()\n\u001b[1;32m    207\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:180\u001b[0m, in \u001b[0;36mEvaluationLoop.on_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39m_logger_connector\u001b[39m.\u001b[39mepoch_end_reached()\n\u001b[1;32m    179\u001b[0m \u001b[39m# hook\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluation_epoch_end(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_outputs)\n\u001b[1;32m    181\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m []  \u001b[39m# free memory\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[39m# hook\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:288\u001b[0m, in \u001b[0;36mEvaluationLoop._evaluation_epoch_end\u001b[0;34m(self, outputs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39m# call the model epoch end\u001b[39;00m\n\u001b[1;32m    287\u001b[0m hook_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtest_epoch_end\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mtesting \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mvalidation_epoch_end\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 288\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_lightning_module_hook(hook_name, output_or_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1356\u001b[0m, in \u001b[0;36mTrainer._call_lightning_module_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1353\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m hook_name\n\u001b[1;32m   1355\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[LightningModule]\u001b[39m\u001b[39m{\u001b[39;00mpl_module\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1356\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1358\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "\u001b[1;32m/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb Cell 45\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X62sZmlsZQ%3D%3D?line=180'>181</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mConfusion Matrix\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X62sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m \u001b[39mprint\u001b[39m(confusion)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X62sZmlsZQ%3D%3D?line=183'>184</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger\u001b[39m.\u001b[39;49mlog_metrics({\u001b[39m'\u001b[39;49m\u001b[39mtest_acc_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m: acc_mean, \u001b[39m'\u001b[39;49m\u001b[39mtest_f1_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m: f1_mean, \u001b[39m'\u001b[39;49m\u001b[39mtest_loss_epoch\u001b[39;49m\u001b[39m'\u001b[39;49m: loss_mean\u001b[39m.\u001b[39;49mitem(), \u001b[39m'\u001b[39;49m\u001b[39mConfusion Matrix\u001b[39;49m\u001b[39m'\u001b[39;49m: confusion}, step\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcurrent_epoch)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X62sZmlsZQ%3D%3D?line=184'>185</a>\u001b[0m \u001b[39mreturn\u001b[39;00m {\u001b[39m'\u001b[39m\u001b[39mConfusion Matrix\u001b[39m\u001b[39m'\u001b[39m: confusion}\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/lightning_utilities/core/rank_zero.py:32\u001b[0m, in \u001b[0;36mrank_zero_only.<locals>.wrapped_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe `rank_zero_only.rank` needs to be set before use\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m rank \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     33\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/lightning_fabric/loggers/tensorboard.py:206\u001b[0m, in \u001b[0;36mTensorBoardLogger.log_metrics\u001b[0;34m(self, metrics, step)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m    205\u001b[0m     m \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m you tried to log \u001b[39m\u001b[39m{\u001b[39;00mv\u001b[39m}\u001b[39;00m\u001b[39m which is currently not supported. Try a dict or a scalar/tensor.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 206\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(m) \u001b[39mfrom\u001b[39;00m \u001b[39mex\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: \n you tried to log [[  14   32   36]\n [  15 1687  112]\n [  11   85 1240]] which is currently not supported. Try a dict or a scalar/tensor."
     ]
    }
   ],
   "source": [
    "trainer.test(test_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Después de completar el entrenamiento\n",
    "epochs = list(range(1, len(pl_model.train_losses) + 1))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, pl_model.train_losses, label='Train Loss', marker='o')\n",
    "#plt.plot(epochs, pl_model.val_losses, label='Validation Loss', marker='o')\n",
    "plt.xlabel('Época')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss vs. Época')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pl_model.confussion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
