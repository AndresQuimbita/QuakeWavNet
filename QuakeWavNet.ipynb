{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (4.17.0)\n",
      "Requirement already satisfied: filelock in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (1.22.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: sacremoses in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: six in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sacremoses->transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sacremoses->transformers) (1.3.1)\n",
      "Requirement already satisfied: ipywidgets in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (8.0.6)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipywidgets) (6.23.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipywidgets) (4.0.7)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipywidgets) (3.0.7)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.6.7)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (8.3.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (1.5.6)\n",
      "Requirement already satisfied: packaging in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (23.1)\n",
      "Requirement already satisfied: psutil in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.9.5)\n",
      "Requirement already satisfied: pyzmq>=20 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (25.1.0)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.3.2)\n",
      "Requirement already satisfied: backcall in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.5.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (6.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.5.1->ipywidgets) (3.8.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel>=4.5.1->ipywidgets) (3.15.0)\n",
      "Collecting pytorch-lightning==1.5.10\n",
      "  Using cached pytorch_lightning-1.5.10-py3-none-any.whl (527 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (1.22.4)\n",
      "Requirement already satisfied: torch>=1.7.* in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (2.0.1)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (0.18.3)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (6.0)\n",
      "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (2023.6.0)\n",
      "Requirement already satisfied: tensorboard>=2.2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (2.13.0)\n",
      "Requirement already satisfied: torchmetrics>=0.4.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (0.11.4)\n",
      "Requirement already satisfied: pyDeprecate==0.3.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (0.3.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (23.1)\n",
      "Requirement already satisfied: typing-extensions in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (4.5.0)\n",
      "Requirement already satisfied: setuptools==59.5.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning==1.5.10) (59.5.0)\n",
      "Requirement already satisfied: requests in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (2.31.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (3.8.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.56.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.4.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (4.23.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.40.0)\n",
      "Requirement already satisfied: filelock in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (3.12.2)\n",
      "Requirement already satisfied: sympy in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (1.12)\n",
      "Requirement already satisfied: networkx in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.7.*->pytorch-lightning==1.5.10) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.7.*->pytorch-lightning==1.5.10) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.7.*->pytorch-lightning==1.5.10) (16.0.6)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (6.7.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.10) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sympy->torch>=1.7.*->pytorch-lightning==1.5.10) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.5.10) (3.2.2)\n",
      "Installing collected packages: pytorch-lightning\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.9.5\n",
      "    Uninstalling pytorch-lightning-1.9.5:\n",
      "      Successfully uninstalled pytorch-lightning-1.9.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lightning-bolts 0.7.0 requires pytorch-lightning<2.0.0,>1.7.0, but you have pytorch-lightning 1.5.10 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pytorch-lightning-1.5.10\n",
      "Requirement already satisfied: nvidia-ml-py3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (7.352.0)\n",
      "Requirement already satisfied: neptune-client in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (1.3.1)\n",
      "Requirement already satisfied: GitPython>=2.0.8 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (3.1.31)\n",
      "Requirement already satisfied: Pillow>=1.1.6 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (9.5.0)\n",
      "Requirement already satisfied: PyJWT in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (2.7.0)\n",
      "Requirement already satisfied: boto3>=1.16.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.26.165)\n",
      "Requirement already satisfied: bravado<12.0.0,>=11.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (11.0.3)\n",
      "Requirement already satisfied: click>=7.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (8.1.3)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (0.18.3)\n",
      "Requirement already satisfied: oauthlib>=2.1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (3.2.2)\n",
      "Requirement already satisfied: packaging in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (23.1)\n",
      "Requirement already satisfied: pandas in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.2.4)\n",
      "Requirement already satisfied: psutil in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (5.9.5)\n",
      "Requirement already satisfied: requests>=2.20.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib>=1.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.3.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.16.0)\n",
      "Requirement already satisfied: swagger-spec-validator>=2.7.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (3.0.3)\n",
      "Requirement already satisfied: urllib3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.26.16)\n",
      "Requirement already satisfied: websocket-client!=1.0.0,>=0.35.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from neptune-client) (1.6.1)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.165 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (1.29.165)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from boto3>=1.16.0->neptune-client) (0.6.1)\n",
      "Requirement already satisfied: bravado-core>=5.16.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (5.17.1)\n",
      "Requirement already satisfied: msgpack in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.0.5)\n",
      "Requirement already satisfied: python-dateutil in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (6.0)\n",
      "Requirement already satisfied: simplejson in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (3.19.1)\n",
      "Requirement already satisfied: monotonic in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (1.6)\n",
      "Requirement already satisfied: typing-extensions in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado<12.0.0,>=11.0.0->neptune-client) (4.5.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from GitPython>=2.0.8->neptune-client) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests>=2.20.0->neptune-client) (2023.5.7)\n",
      "Requirement already satisfied: jsonschema in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from swagger-spec-validator>=2.7.4->neptune-client) (4.17.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pandas->neptune-client) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pandas->neptune-client) (1.22.4)\n",
      "Requirement already satisfied: jsonref in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from bravado-core>=5.16.1->bravado<12.0.0,>=11.0.0->neptune-client) (1.1.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->GitPython>=2.0.8->neptune-client) (5.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (23.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.19.3)\n",
      "Requirement already satisfied: fqdn in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (2.4)\n",
      "Requirement already satisfied: rfc3339-validator in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (0.1.4)\n",
      "Requirement already satisfied: rfc3987 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.3.8)\n",
      "Requirement already satisfied: uri-template in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from isoduration->jsonschema->swagger-spec-validator>=2.7.4->neptune-client) (1.2.3)\n",
      "Requirement already satisfied: lightning-bolts in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-bolts) (1.22.4)\n",
      "Collecting pytorch-lightning<2.0.0,>1.7.0 (from lightning-bolts)\n",
      "  Using cached pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n",
      "Requirement already satisfied: torchmetrics in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-bolts) (0.11.4)\n",
      "Requirement already satisfied: lightning-utilities>0.3.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-bolts) (0.9.0)\n",
      "Requirement already satisfied: torchvision>=0.10.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-bolts) (0.15.2)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-bolts) (2.13.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-utilities>0.3.1->lightning-bolts) (23.1)\n",
      "Requirement already satisfied: typing-extensions in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from lightning-utilities>0.3.1->lightning-bolts) (4.5.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.0.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (4.65.0)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (6.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2023.6.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (1.56.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (2.21.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (3.4.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (4.23.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (59.5.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (2.3.6)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from tensorboard>=2.9.1->lightning-bolts) (0.40.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torchvision>=0.10.0->lightning-bolts) (9.5.0)\n",
      "Requirement already satisfied: filelock in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.12.2)\n",
      "Requirement already satisfied: sympy in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.12)\n",
      "Requirement already satisfied: networkx in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (2.0.0)\n",
      "Requirement already satisfied: cmake in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (16.0.6)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (3.8.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (4.9)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (1.16.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->lightning-bolts) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard>=2.9.1->lightning-bolts) (6.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->lightning-bolts) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->lightning-bolts) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->lightning-bolts) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->lightning-bolts) (2.1.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.9.1->lightning-bolts) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->lightning-bolts) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->lightning-bolts) (3.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sympy->torch>=1.10.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts) (1.3.0)\n",
      "Installing collected packages: pytorch-lightning\n",
      "  Attempting uninstall: pytorch-lightning\n",
      "    Found existing installation: pytorch-lightning 1.5.10\n",
      "    Uninstalling pytorch-lightning-1.5.10:\n",
      "      Successfully uninstalled pytorch-lightning-1.5.10\n",
      "Successfully installed pytorch-lightning-1.9.5\n",
      "Requirement already satisfied: torchmetrics in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (0.11.4)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torchmetrics) (1.22.4)\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torchmetrics) (2.0.1)\n",
      "Requirement already satisfied: packaging in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torchmetrics) (23.1)\n",
      "Requirement already satisfied: filelock in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->torchmetrics) (59.5.0)\n",
      "Requirement already satisfied: wheel in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.1->torchmetrics) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install ipywidgets\n",
    "!pip install pytorch-lightning==1.5.10\n",
    "!pip install nvidia-ml-py3\n",
    "!pip install neptune-client\n",
    "!pip install lightning-bolts\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model, Wav2Vec2Config\n",
    "import torch\n",
    "from transformers.models.wav2vec2.modeling_wav2vec2 import Wav2Vec2FeatureEncoder, Wav2Vec2NoLayerNormConvLayer, Wav2Vec2LayerNormConvLayer\n",
    "from torch import nn\n",
    "from transformers.activations import ACT2FN\n",
    "import ipywidgets\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import torchaudio\n",
    "import torchtext\n",
    "import pytorch_lightning as pl\n",
    "import nvidia_smi\n",
    "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
    "from pytorch_lightning.loggers import NeptuneLogger\n",
    "from IPython.display import display, HTML\n",
    "from dataclasses import dataclass, field\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "from torchmetrics import Accuracy\n",
    "from torchmetrics import F1Score\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify if the GPU is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 27 14:54:15 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A4000    Off  | 00000000:B3:00.0  On |                  Off |\n",
      "| 41%   42C    P8    21W / 140W |   1340MiB / 16376MiB |     39%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2029      G   /usr/lib/xorg/Xorg                 39MiB |\n",
      "|    0   N/A  N/A      4091      G   /usr/lib/xorg/Xorg                157MiB |\n",
      "|    0   N/A  N/A      4241      G   /usr/bin/gnome-shell               80MiB |\n",
      "|    0   N/A  N/A      6313      G   ...RendererForSitePerProcess      168MiB |\n",
      "|    0   N/A  N/A      6728      C   ...da3/envs/coEnv/bin/python      698MiB |\n",
      "|    0   N/A  N/A      8661      G   /usr/lib/firefox/firefox          182MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch Lightning Version: 1.9.5\n",
      "Device name: b'NVIDIA RTX A4000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"Pytorch Lightning Version: {pl.__version__}\")\n",
    "nvidia_smi.nvmlInit()\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "print(f\"Device name: {nvidia_smi.nvmlDeviceGetName(handle)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': 'wav2vec2-sound_sismic_train',\n",
       " 'lr': 1e-05,\n",
       " 'w_decay': 0,\n",
       " 'bs': 16,\n",
       " 'patience': 30,\n",
       " 'hold_epochs': 20,\n",
       " 'accum_grads': 4,\n",
       " 'pretrained': 'facebook/wav2vec2-base-960h',\n",
       " 'wav2vec2_processor': 'facebook/wav2vec2-base-960h',\n",
       " 'freeze_finetune_updates': 0,\n",
       " 'warmup_epochs': 40,\n",
       " 'apply_mask': True,\n",
       " 'mask_time_length': 10,\n",
       " 'max_epochs': 300}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version = \"wav2vec2-sound_sismic_train\" #@param {type: \"string\"}\n",
    "lr = 1e-5#@param {type: \"number\"}\n",
    "w_decay = 0#@param {type: \"number\"}\n",
    "bs = 16#@param {type: \"integer\"}\n",
    "accum_grads = 4#@param {type: \"integer\"}\n",
    "patience = 30#@param {type: \"integer\"}\n",
    "max_epochs = 300#@param {type: \"integer\"}\n",
    "warmup_steps = 1000#@param {type: \"integer\"}\n",
    "hold_epochs = 20#@param {type: \"integer\"}\n",
    "pretrained = \"facebook/wav2vec2-base-960h\"#@param {type: \"string\"}\n",
    "wav2vec2_processor = \"facebook/wav2vec2-base-960h\"#@param {type: \"string\"}\n",
    "freeze_finetune_updates = 0#@param {type: \"integer\"}\n",
    "warmup_epochs = 40#@param {type: \"integer\"}\n",
    "apply_mask=True#@param {type: \"boolean\"}\n",
    "mask_time_length= 10#@param {type: \"integer\"}, era 1\n",
    "\n",
    "# Define hyperparameters\n",
    "hparams = {\"version\": version,\n",
    "          \"lr\": lr,\n",
    "          \"w_decay\": w_decay,\n",
    "          \"bs\": bs,\n",
    "          \"patience\": patience,\n",
    "          \"hold_epochs\":hold_epochs,\n",
    "          \"accum_grads\": accum_grads,\n",
    "          \"pretrained\":pretrained,\n",
    "          \"wav2vec2_processor\": wav2vec2_processor,\n",
    "          \"freeze_finetune_updates\":freeze_finetune_updates,\n",
    "          \"warmup_epochs\":warmup_epochs,\n",
    "          \"apply_mask\":apply_mask,\n",
    "          \"mask_time_length\":mask_time_length,\n",
    "          \"max_epochs\": max_epochs}\n",
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the original processor from Wav2Vec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = Wav2Vec2Processor.from_pretrained(hparams[\"wav2vec2_processor\"], return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav2Vec2Processor:\n",
      "- feature_extractor: Wav2Vec2FeatureExtractor {\n",
      "  \"do_normalize\": true,\n",
      "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
      "  \"feature_size\": 1,\n",
      "  \"padding_side\": \"right\",\n",
      "  \"padding_value\": 0.0,\n",
      "  \"return_attention_mask\": true,\n",
      "  \"sampling_rate\": 16000\n",
      "}\n",
      "\n",
      "- tokenizer: PreTrainedTokenizer(name_or_path='facebook/wav2vec2-base-960h', vocab_size=32, model_max_len=9223372036854775807, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>'})\n"
     ]
    }
   ],
   "source": [
    "print(processor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalize the model to accept n channels instead of just 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wav2Vec2GroupNormConvLayer(nn.Module):\n",
    "    def __init__(self, config, num_input_channels=1, layer_id=0):\n",
    "        super().__init__()\n",
    "        self.num_input_channels = num_input_channels\n",
    "        self.in_conv_dim = config.conv_dim[layer_id - 1] if layer_id > 0 else self.num_input_channels\n",
    "        self.out_conv_dim = config.conv_dim[layer_id]\n",
    "\n",
    "        self.conv = nn.Conv1d(\n",
    "            self.in_conv_dim,\n",
    "            self.out_conv_dim,\n",
    "            kernel_size=config.conv_kernel[layer_id],\n",
    "            stride=config.conv_stride[layer_id],\n",
    "            bias=config.conv_bias,\n",
    "        )\n",
    "        self.activation = ACT2FN[config.feat_extract_activation]\n",
    "\n",
    "        self.layer_norm = nn.GroupNorm(num_groups=self.out_conv_dim, num_channels=self.out_conv_dim, affine=True)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.conv(hidden_states)\n",
    "        hidden_states = self.layer_norm(hidden_states)\n",
    "        hidden_states = self.activation(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "class Wav2Vec2_ChannelFeatureEncoder(nn.Module):\n",
    "    \"\"\"Construct the features from raw audio waveform\"\"\"\n",
    "\n",
    "    def __init__(self, config, num_input_channels=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_input_channels = num_input_channels\n",
    "        \n",
    "        if config.feat_extract_norm == \"group\":\n",
    "            conv_layers = [Wav2Vec2GroupNormConvLayer(config, num_input_channels= self.num_input_channels,layer_id=0)] + [\n",
    "                Wav2Vec2NoLayerNormConvLayer(config, layer_id=i + 1) for i in range(config.num_feat_extract_layers - 1)\n",
    "            ]\n",
    "        elif config.feat_extract_norm == \"layer\":\n",
    "            conv_layers = [\n",
    "                Wav2Vec2LayerNormConvLayer(config, layer_id=i) for i in range(config.num_feat_extract_layers)\n",
    "            ]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"`config.feat_extract_norm` is {config.feat_extract_norm}, but has to be one of ['group', 'layer']\"\n",
    "            )\n",
    "        self.conv_layers = nn.ModuleList(conv_layers)\n",
    "        self.gradient_checkpointing = False\n",
    "        self._requires_grad = True\n",
    "\n",
    "    def _freeze_parameters(self):\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "        self._requires_grad = False\n",
    "\n",
    "    def forward(self, input_values):\n",
    "        hidden_states = input_values[:] # mudou para que receba todos os canais (4)\n",
    "        #print(\"hidden_states\", hidden_states.shape)\n",
    "\n",
    "        # make sure hidden_states require grad for gradient_checkpointing\n",
    "        if self._requires_grad and self.training:\n",
    "            hidden_states.requires_grad = True\n",
    "\n",
    "        for conv_layer in self.conv_layers:\n",
    "            if self._requires_grad and self.gradient_checkpointing and self.training:\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                hidden_states = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(conv_layer),\n",
    "                    hidden_states,\n",
    "                )\n",
    "            else:\n",
    "                hidden_states = conv_layer(hidden_states)\n",
    "\n",
    "        return hidden_states\n",
    "\n",
    "# Crio o novo modelo que herda os processos de Wav2Vec2, mas usa o extrator de features baseado em 4 canais\n",
    "class Wav2Vec2_ChannelModel(Wav2Vec2Model):\n",
    "    def __init__(self, config: Wav2Vec2Config, num_input_channels=1):\n",
    "        super().__init__(config)\n",
    "\n",
    "        #del self.feature_extractor\n",
    "        self.feature_extractor = Wav2Vec2_ChannelFeatureEncoder(config, num_input_channels=num_input_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2_ChannelModel: ['lm_head.weight', 'wav2vec2.feature_extractor.conv_layers.6.conv.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2_ChannelModel were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2_ChannelModel.from_pretrained(\"facebook/wav2vec2-base-960h\",\n",
    "                                                 conv_dim = (512, 512, 512,512,512,512),\n",
    "                                                 conv_stride = (5, 2, 2,2,2,2),\n",
    "                                                 conv_kernel = (10, 3, 3,3,3,2),\n",
    "                                                 num_feat_extract_layers = 6,\n",
    "                                                 num_input_channels = 1,\n",
    "                                                 ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wav2Vec2_ChannelModel(\n",
      "  (feature_extractor): Wav2Vec2_ChannelFeatureEncoder(\n",
      "    (conv_layers): ModuleList(\n",
      "      (0): Wav2Vec2GroupNormConvLayer(\n",
      "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "        (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
      "      )\n",
      "      (1-4): 4 x Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "      (5): Wav2Vec2NoLayerNormConvLayer(\n",
      "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
      "        (activation): GELUActivation()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (feature_projection): Wav2Vec2FeatureProjection(\n",
      "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    (projection): Linear(in_features=512, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): Wav2Vec2Encoder(\n",
      "    (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
      "      (conv): Conv1d(768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
      "      (padding): Wav2Vec2SamePadLayer()\n",
      "      (activation): GELUActivation()\n",
      "    )\n",
      "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (layers): ModuleList(\n",
      "      (0-11): 12 x Wav2Vec2EncoderLayer(\n",
      "        (attention): Wav2Vec2Attention(\n",
      "          (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (feed_forward): Wav2Vec2FeedForward(\n",
      "          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (intermediate_act_fn): GELUActivation()\n",
      "          (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DO THE TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split completed.\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#import os\n",
    "#import shutil\n",
    "\n",
    "# Define la ruta de la carpeta que contiene los archivos de audio\n",
    "#input_folder = '/media/cslab03/TOSHIBA EXT/TESIS/DataSet/AudioSismig/'\n",
    "\n",
    "# Lista todos los archivos de la carpeta\n",
    "#files = [os.path.join(input_folder, file) for file in os.listdir(input_folder)]\n",
    "\n",
    "# Define las proporciones para train, test y validation sets\n",
    "#train_ratio = 0.7\n",
    "#test_ratio = 0.15\n",
    "#validation_ratio = 0.15\n",
    "\n",
    "# Divide los datos en train, test y validation sets\n",
    "#train_files, temp_files = train_test_split(files, test_size=1 - train_ratio)\n",
    "#test_files, validation_files = train_test_split(temp_files, test_size=validation_ratio / (test_ratio + validation_ratio))\n",
    "\n",
    "# Define las carpetas de salida\n",
    "#output_folder = './output/'\n",
    "#os.makedirs(os.path.join(output_folder, 'train'), exist_ok=True)\n",
    "#os.makedirs(os.path.join(output_folder, 'test'), exist_ok=True)\n",
    "#os.makedirs(os.path.join(output_folder, 'validation'), exist_ok=True)\n",
    "\n",
    "# Copia los archivos a las carpetas correspondientes\n",
    "#for file in train_files:\n",
    " #   shutil.copy(file, os.path.join(output_folder, 'train'))\n",
    "#for file in test_files:\n",
    "    #shutil.copy(file, os.path.join(output_folder, 'test'))\n",
    "#for file in validation_files:\n",
    "    #shutil.copy(file, os.path.join(output_folder, 'validation'))\n",
    "\n",
    "print(\"Data split completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANSYN_Dataset_SE(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, filenames, audio_path):\n",
    "        self.filenames = filenames\n",
    "        self.audio_path = audio_path\n",
    "\n",
    "    def process_audio(self, signal, new_sr):\n",
    "        # right pad if neccesary\n",
    "        length_signal = signal.shape[1]\n",
    "        if length_signal < 53363:\n",
    "            num_missing_samples = 53363 - length_signal\n",
    "            last_dim_padding = (0, num_missing_samples)\n",
    "            signal = torch.nn.functional.pad(signal, last_dim_padding)\n",
    "        elif length_signal > 53363:\n",
    "            signal = signal[:,:53363]\n",
    "        return signal\n",
    "\n",
    "    def normalize_layer(self, feats):\n",
    "        with torch.no_grad():\n",
    "            feats = torch.nn.functional.layer_norm(feats, feats.shape)\n",
    "        return feats\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        feats, _ = torchaudio.load(self.audio_path + self.filenames[index])\n",
    "\n",
    "        feats = self.process_audio(feats, 16000)\n",
    "        feats = self.normalize_layer(feats)\n",
    "        \n",
    "        \n",
    "        if 'EXPL' in self.filenames[index]:\n",
    "            target = torch.tensor(int('00')).long() \n",
    "        elif 'HB' in self.filenames[index]:\n",
    "            target = torch.tensor(int('01')).long() \n",
    "        elif 'LP' in self.filenames[index]:\n",
    "            target = torch.tensor(int('02')).long()\n",
    "        elif 'TRBA' in self.filenames[index]:\n",
    "            target = torch.tensor(int('03')).long()\n",
    "        elif 'TRESP' in self.filenames[index]:\n",
    "            target = torch.tensor(int('04')).long()\n",
    "        elif 'VLP' in self.filenames[index]:\n",
    "            target = torch.tensor(int('05')).long()\n",
    "        elif 'VT' in self.filenames[index]:\n",
    "            target = torch.tensor(int('06')).long()\n",
    "        \n",
    "        return {\"input_values\": feats, \"target\":target}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = os.listdir('/home/cslab03/Desktop/QuakeWavNet/output/train/')\n",
    "X_test = os.listdir('/home/cslab03/Desktop/QuakeWavNet/output/test/')\n",
    "X_val = os.listdir('/home/cslab03/Desktop/QuakeWavNet/output/validation/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2e55d06a9ef7dcd44da6bf9fea6c372e_BDF_BTAM_LP.wav\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ANSYN_Dataset_SE(X_train, '/home/cslab03/Desktop/QuakeWavNet/output/train/')\n",
    "val_dataset =  ANSYN_Dataset_SE(X_val, '/home/cslab03/Desktop/QuakeWavNet/output/validation/')\n",
    "test_dataset = ANSYN_Dataset_SE(X_test, '/home/cslab03/Desktop/QuakeWavNet/output/test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequncia de amostragem aceita pelo modelo: 16000\n",
      "Input values dimenso: torch.Size([1, 1, 53363])\n",
      "{'input_values': tensor([[[-0.9939, -0.8431, -0.8137,  ...,  0.5243,  0.5243,  0.5243]]]), 'attention_mask': tensor([[1]], dtype=torch.int32)}\n"
     ]
    }
   ],
   "source": [
    "target_sampling_rate = processor.feature_extractor.sampling_rate\n",
    "print(f\"Frequncia de amostragem aceita pelo modelo: {target_sampling_rate}\")\n",
    "# Conferindo se os dados de entrada no geram erro no processor\n",
    "inputs = processor(train_dataset[5][\"input_values\"], sampling_rate=target_sampling_rate, return_tensors=\"pt\")\n",
    "print(f'Input values dimenso: {inputs[\"input_values\"].shape}')\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimenses de entrada do modelo:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimenses de sada do modelo: \n",
      " torch.Size([1, 333, 768])\n"
     ]
    }
   ],
   "source": [
    "print('Dimenses de entrada do modelo:')\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "last_hidden_states = outputs.last_hidden_state\n",
    "\n",
    "print('Dimenses de sada do modelo: \\n',last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DataCollatorWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"target\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        #print('batch', batch)\n",
    "        with self.processor.as_target_processor(): labels_batch = self.processor.pad( label_features, padding=True,max_length=self.max_length_labels,pad_to_multiple_of=self.pad_to_multiple_of_labels,return_tensors=\"pt\",)\n",
    "        print('labels_batch', labels_batch)\n",
    "\n",
    "\n",
    "        labels = labels_batch[\"input_ids\"]\n",
    "\n",
    "        batch[\"target\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(processor=processor,\n",
    "                                        #max_length=188,\n",
    "                                        padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nmero de minibatches de treinamento: 3813\n",
      "Nmero de minibatches de validao: 818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 6, 2, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch labels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 2, 2, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 6, 2, 6, 6, 6, 2, 6, 2, 6, 2, 6, 2, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 1, 2, 2, 2, 6, 2, 2, 6, 6, 2, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 6, 2, 2, 6, 2, 2, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 4, 1, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 2, 2, 6, 2, 2, 2, 6, 2, 1, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "Dimenses dos dados de um minibatch - Audio: torch.Size([16, 1, 53363])\n",
      "\n",
      "Dimenses dos dados de um minibatch - Target: torch.Size([16])\n",
      "Valores mnimo e mximo entrada:  tensor(-16.5341) tensor(19.3978)\n",
      "Valores mnimo e mximo sada:  tensor(2) tensor(6)\n",
      "Tipo dos dados dos udios:          <class 'torch.Tensor'>\n",
      "Tipo das classes das classes:        <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "batch_size = hparams[\"bs\"]\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                              collate_fn = data_collator,\n",
    "                              shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                            collate_fn = data_collator,\n",
    "                            shuffle=False, num_workers=4)\n",
    "\n",
    "print('Nmero de minibatches de treinamento:', len(train_dataloader))\n",
    "print('Nmero de minibatches de validao:', len(val_dataloader))\n",
    "\n",
    "batch = next(iter(train_dataloader))\n",
    "#print(batch)\n",
    "\n",
    "x_train, y_train = batch['input_values'], batch['target']\n",
    "print(\"\\nDimenses dos dados de um minibatch - Audio:\", x_train.size())\n",
    "# print(\"\\nDimenses dos dados de um minibatch:\", padding_mask.size())\n",
    "print(\"\\nDimenses dos dados de um minibatch - Target:\", y_train.size())\n",
    "print(\"Valores mnimo e mximo entrada: \", torch.min(x_train), torch.max(x_train))\n",
    "print(\"Valores mnimo e mximo sada: \", torch.min(y_train), torch.max(y_train))\n",
    "print(\"Tipo dos dados dos udios:         \", type(x_train))\n",
    "print(\"Tipo das classes das classes:       \", type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 7\n",
    "f1 = F1Score(num_classes=n_classes, average='macro', task='multiclass')\n",
    "accuracy = Accuracy(num_classes=n_classes,task='multiclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wav2Vec2_sound_detection(pl.LightningModule):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hparams.update(hparams)\n",
    "\n",
    "        self.freeze_finetune_updates = hparams[\"freeze_finetune_updates\"]\n",
    "\n",
    "        #self.model = model4c\n",
    "        self.val_f1_scores = []\n",
    "        self.test_f1_scores = []\n",
    "        \n",
    "        self.model = Wav2Vec2_ChannelModel.from_pretrained(hparams[\"pretrained\"],\n",
    "                                                 conv_dim = (512, 512, 512, 512, 512, 512),\n",
    "                                                 conv_stride = (5, 2, 2, 2, 2, 2),\n",
    "                                                 conv_kernel = (10, 3, 3, 3, 3, 2),\n",
    "                                                 num_feat_extract_layers = 6,\n",
    "                                                 apply_spec_augment=hparams[\"apply_mask\"],\n",
    "                                                 #mask_time_length=hparams[\"mask_time_length\"],\n",
    "                                                 num_input_channels = 1,\n",
    "                                                 ignore_mismatched_sizes=True)\n",
    "\n",
    "\n",
    "        # self.model.feature_extractor._freeze_parameters()\n",
    "\n",
    "        # freeze base-model\n",
    "        # for param in self.model.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.projector = nn.Linear(self.model.config.hidden_size, self.model.config.classifier_proj_size)\n",
    "        n_classes = 7\n",
    "        self.final_layer = nn.Linear(self.model.config.classifier_proj_size, n_classes)\n",
    "\n",
    "    def forward(self, samples):\n",
    "\n",
    "        ft = self.freeze_finetune_updates <= self.trainer.global_step\n",
    "\n",
    "        with torch.no_grad() if not ft else contextlib.ExitStack():\n",
    "            hidden_states = self.model(**samples).last_hidden_state\n",
    "\n",
    "        padding_mask = self.model._get_feature_vector_attention_mask(hidden_states.shape[1], samples[\"attention_mask\"])\n",
    "\n",
    "        hidden_states[~padding_mask] = 0.0\n",
    "\n",
    "        pooled_output = hidden_states.sum(dim=1) / padding_mask.sum(dim=1).view(-1, 1)\n",
    "\n",
    "        proj_pooled = self.projector(pooled_output)\n",
    "\n",
    "        preds = self.final_layer(proj_pooled)\n",
    "\n",
    "        return F.log_softmax(preds, dim=1)\n",
    "\n",
    "    def _get_feature_vector_attention_mask(self, feature_vector_length: int, attention_mask: torch.LongTensor):\n",
    "        output_lengths = self._get_feat_extract_output_lengths(attention_mask.sum(-1)).to(torch.long)\n",
    "        batch_size = attention_mask.shape[0]\n",
    "\n",
    "        attention_mask = torch.zeros(\n",
    "            (batch_size, feature_vector_length), dtype=attention_mask.dtype, device=attention_mask.device\n",
    "        )\n",
    "\n",
    "        attention_mask[(torch.arange(attention_mask.shape[0], device=attention_mask.device), output_lengths - 1)] = 1\n",
    "        attention_mask = attention_mask.flip([-1]).cumsum(-1).flip([-1]).bool()\n",
    "        return attention_mask\n",
    "        \n",
    "        \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "\n",
    "        y_value = train_batch.pop(\"target\")\n",
    "        log_softs = self.forward(train_batch)\n",
    "    \n",
    "\n",
    "        loss = F.nll_loss(log_softs, y_value)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        self.log('loss_step', loss, on_step=True, prog_bar=True)\n",
    "        \n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        \n",
    "\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "\n",
    "        y_value = val_batch.pop(\"target\")\n",
    "\n",
    "        log_softs = self.forward(val_batch)\n",
    "        preds = torch.argmax(log_softs, dim=1)\n",
    "\n",
    "        val_acc = accuracy(preds.cpu(), y_value.cpu())\n",
    "        val_f1 = f1(preds.cpu(), y_value.cpu())\n",
    "        val_loss = F.nll_loss(log_softs, y_value)\n",
    "\n",
    "        self.log('val_acc', val_acc, prog_bar=True)\n",
    "        self.log('val_f1', val_f1, prog_bar=True)\n",
    "        self.log('val_loss', val_loss, prog_bar=True)\n",
    "\n",
    "        return {\"val_acc_step\": val_acc, \"val_f1_step\": val_f1, \"val_loss_step\": val_loss}\n",
    "\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        acc_mean = torch.stack([x['val_acc_step'] for x in outputs]).mean()\n",
    "        f1_mean = torch.stack([x['val_f1_step'] for x in outputs]).mean()\n",
    "        loss_mean = torch.stack([x['val_loss_step'] for x in outputs]).mean()\n",
    "\n",
    "        self.log(\"val_acc\", acc_mean, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1_mean, prog_bar=True)\n",
    "        self.log(\"val_loss\", loss_mean, prog_bar=True)\n",
    "\n",
    "        self.val_f1_scores.append(f1_mean)\n",
    "    import torch.functional as F\n",
    "    \n",
    "    \"\"\"def validation_epoch_end(self, outputs):\n",
    "        acc_mean = torch.stack([x['val_acc_step'] for x in outputs]).mean()\n",
    "        f1_mean = torch.stack([x['val_f1_step'] for x in outputs]).mean()\n",
    "        loss_mean = torch.stack([x['val_loss_step'] for x in outputs]).mean()\n",
    "\n",
    "        self.log(\"val_acc\", acc_mean, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1_mean, prog_bar=True)\n",
    "        self.log(\"val_loss\", loss_mean, prog_bar=True)\"\"\"\n",
    "\n",
    "    def test_step(self, test_batch, batch_idx):\n",
    "\n",
    "        y_value = test_batch.pop(\"target\")\n",
    "\n",
    "        log_softs = self.forward(test_batch)\n",
    "        preds = torch.argmax(log_softs, dim=1)\n",
    "\n",
    "        test_acc = accuracy(preds.cpu(), y_value.cpu())\n",
    "        test_f1 = f1(preds.cpu(), y_value.cpu())\n",
    "        test_loss = F.nll_loss(log_softs, y_value)\n",
    "\n",
    "        self.log('test_acc', test_acc, prog_bar=True)\n",
    "        self.log('test_f1', test_f1, prog_bar=True)\n",
    "        self.log('test_loss', test_loss, prog_bar=True)\n",
    "\n",
    "        return {\"test_acc_step\": test_acc, \"test_f1_step\": test_f1,  \"test_loss_step\": test_loss}\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        acc_mean = torch.stack([x['test_acc_step'] for x in outputs]).mean()\n",
    "        f1_mean = torch.stack([x['test_f1_step'] for x in outputs]).mean()\n",
    "        loss_mean = torch.stack([x['test_loss_step'] for x in outputs]).mean()\n",
    "\n",
    "        self.log(\"test_acc\", acc_mean, prog_bar=True)\n",
    "        self.log(\"test_f1\", f1_mean, prog_bar=True)\n",
    "        self.log(\"test_loss\", loss_mean, prog_bar=True)\n",
    "        \n",
    "        self.test_f1_scores.append(f1_mean)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                         lr=self.hparams[\"lr\"],\n",
    "                         betas=(0.9,0.98),\n",
    "                         eps=1e-6,\n",
    "                         weight_decay=self.hparams[\"w_decay\"])\n",
    "\n",
    "        scheduler = LinearWarmupCosineAnnealingLR(optimizer,\n",
    "                                                  eta_min=0,\n",
    "                                                  warmup_start_lr=self.hparams[\"lr\"],\n",
    "                                                  warmup_epochs=self.hparams[\"warmup_epochs\"],\n",
    "                                                  max_epochs=self.hparams[\"max_epochs\"])\n",
    "\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJjMWEyNTJlZS05ZDI5LTQzZjktYTkzNy00MDczMmZhODU3OWUifQ==\",\n",
    "    project='kgrosero/IA025-Project-wav2vec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2_ChannelModel: ['lm_head.weight', 'wav2vec2.feature_extractor.conv_layers.6.conv.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2_ChannelModel were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/tmp/ipykernel_6728/949965054.py:166: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  scheduler = LinearWarmupCosineAnnealingLR(optimizer,\n",
      "\n",
      "  | Name        | Type                  | Params\n",
      "------------------------------------------------------\n",
      "0 | model       | Wav2Vec2_ChannelModel | 93.8 M\n",
      "1 | projector   | Linear                | 196 K \n",
      "2 | final_layer | Linear                | 1.8 K \n",
      "------------------------------------------------------\n",
      "94.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "94.0 M    Total params\n",
      "376.184   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9acfbee8af04ed88e2ffa2913f8a5e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d69c40cee64d45a0faf9145c031005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batchlabels_batch    {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "https://app.neptune.ai/kgrosero/IA025-Project-wav2vec2/e/IAP-54\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bcf1abb3864b57bc0d0bdfbecb8065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch labels_batch  {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " \n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9281823d5b42f78a25a241aca5a32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " \n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "Unexpected error occurred in Neptune background thread: Killing Neptune asynchronous thread. All data is safe on disk and can be later synced manually using `neptune sync` command.\n",
      "labels_batchlabels_batch labels_batch "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread NeptuneAsyncOpProcessor:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/operation_processors/async_operation_processor.py\", line 230, in run\n",
      "    super().run()\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/threading/daemon.py\", line 53, in run\n",
      "    self.work()\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/operation_processors/async_operation_processor.py\", line 246, in work\n",
      "    self.process_batch([element.obj for element in batch], batch[-1].ver)\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/threading/daemon.py\", line 76, in wrapper\n",
      "    result = func(self_, *args, **kwargs)\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/operation_processors/async_operation_processor.py\", line 259, in process_batch\n",
      "    processed_count, errors = self._processor._backend.execute_operations(\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 467, in execute_operations\n",
      "    self._execute_upload_operations_with_400_retry(\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 571, in _execute_upload_operations_with_400_retry\n",
      "    return self._execute_upload_operations(\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/backends/hosted_neptune_backend.py\", line 525, in _execute_upload_operations\n",
      "    upload_errors = upload_file_attribute(\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/backends/hosted_file_operations.py\", line 115, in upload_file_attribute\n",
      "    _multichunk_upload_with_retry(\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/backends/hosted_file_operations.py\", line 286, in _multichunk_upload_with_retry\n",
      "    return _multichunk_upload(upload_entry, swagger_client, query_params, multipart_config, urlset)\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/internal/backends/hosted_file_operations.py\", line 331, in _multichunk_upload\n",
      "    for idx, chunk in enumerate(chunker.generate()):\n",
      "  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/neptune/common/storage/datastream.py\", line 72, in generate\n",
      "    if last_change and last_change < os.stat(self._filename).st_mtime:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/cslab03/Desktop/QuakeWavNet/.neptune/None/version_None/checkpoints/epoch=0-step=3.ckpt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc3bbcf340748a0b886c3c1594fb863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      " {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b08aef022941a38c18507f86591978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batchlabels_batch\n",
      "  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} labels_batch \n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb23e84c939c4e7ba7b6e4e5162176db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}  \n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4def66d38e459f911e2805500ee412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " \n",
      "{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0daacc0c23ec4f1d935114f8349a5c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d169177e577a4537aecbb9c5cbe5f24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b029d5669b274bc0a0f28c6383a263d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      " {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06df011241bb4c35b96128b6ce4be9ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch labels_batch  {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9cd10d2d4141419e829f28a5b9c13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0805aa4645674b90b376175f47a75642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}  \n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f827b4b8214ed6ba3d57cce984ca59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "\n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a267e2f0d23494c8ae8e53bd81bb07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "\n",
      " {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batchlabels_batch    {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batchlabels_batch\n",
      "  {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9eb0b993e2645e3810d652d4ca55eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " \n",
      "\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61c234ea430407db00ac2237a588c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d9945df4ef54a7581f232be82ba55eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batchlabels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "  labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a055afefaa9a402db943ae164f23178c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66b3f624684f4c939dee8437b5db46d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55b0e264988431aa69b2bb7387c2438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " \n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfd677a1a3874bfc85c3cabfbd366ecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batchlabels_batch\n",
      "  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ac6e7c9a9541d886d14ca396c58067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cabdda152804c0cb0d0e59763b14fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7587965d32584e2292e5238675d38aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batchlabels_batch\n",
      "  labels_batch{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06c3b35421a4504b0214636bdd4f719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batchlabels_batch\n",
      "  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      " \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7feca81a701043c5b95a65ec8bbc8b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batchlabels_batch\n",
      "  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65b649e095944ffa04d3a813e3c4357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} labels_batch{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      " {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c76eaadfdb54a3d828aed78474b163a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " labels_batch{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314d0cc1575d4a939b34583936737f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c8b2d916744ee9bd51c4c0b4628054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch labels_batch{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f5e3c5441d438fb8ee3ff827a6c42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      " labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch labels_batch  {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a689a154840c48b9979b263466e26e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch labels_batch{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "\n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b50cd087e44c6785eda6e6490fbfaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " labels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " labels_batch labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "424471a7439f42f1914a30395f538669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fddaacbc00248a1bf45afacfcbc96e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1efe23a2dd464eb68043a70d8558d23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch \n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9c4237a71b40f286c435d154a8e959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b390cf637a4b3b9cd3548936265ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839870b60252490594eb58dcec794fde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba40a313d7a4441851d9fa9d7077b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e01ed345e04a33b6e60a9032e10109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch labels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028f9003bb4b4a74b1eca2ebdbe7dbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2497766593854ec790ffdd9f54913fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31afdfaf9a7c4d7e8648f1639caad4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} labels_batchlabels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158629d7bf714214b84da2b09fc6bde5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "\n",
      " {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4052b02662c54f868b2d6e715a9addcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c094f4d3f546e8824b8f58e4331cda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e224e4c31cf44d799887cd23b8787f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "625898abb0b043c18f0460d1a1865d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6d738c893441a58c20e94f7bf0303f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d48223f82124cccb13539441f7e3570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch labels_batchlabels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00914c585a204c20b6c240e862aa7687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " \n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "labels_batch  {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7e190d77b54b0ebfdf8ba4e5a415fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd14aef1d3946caa5f802fa5ebb0f53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " labels_batchlabels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73683190ee134057be4a081f2a0e4c42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batchlabels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "\n",
      " {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be0a36542cb46ecb528e275195c1d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a7680f69b746a1ba1f09794b20d320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "labels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e490c6389c540088a6544fe66410564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "\n",
      " {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batchlabels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41e17563a86a4c129d82289de1fd44cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}  \n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f8601633374e7996029aa442faf978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4afc77d838e4396b7b5129941bb8daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90df239391ff40b88d34fbe0cb4ee880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901010b1a034448aa147d5dde939fc23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4944d2fcb00f40c2b706e077f2f2e7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6a36bdbb024415bc4e5a73de2bfb2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch labels_batch labels_batch{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} labels_batch\n",
      "\n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da3fe3d6f3c41cb99d2a5eed78ece4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "labels_batch{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba48fc3d777413e927fbf14ab831fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch\n",
      " labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c4b30f5e424c52898d662e5c16b35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a62dec50a5b04de183653c7f2acef04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} labels_batch\n",
      " {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7724825709e24d5e8186126bbd77e409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1015943f6a4841a51060cd8e9ce301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18a0fd603cb748d3ad47bde9484a16e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6728f1f53c402fb295cfe409879c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b670cbd74347f1809d0222fbe9e2f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " labels_batchlabels_batch{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01caaab81334b389d8b68354a0caa6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch labels_batch labels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch labels_batch{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f19e136f7546608d30f9c7d71f9511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} labels_batch\n",
      "\n",
      " {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a303e9ec57747e18adefcb587063e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc1f020c3d14cc79da947cb7b58fd39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1c78b711774fd79a3eea79ff68c9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " \n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98c94f53fd14549b533c1d5e2e611f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f2e4a5e71b47668c3cd05fa76b30d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c064b16c05c14dceb268e3c986e5b248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch \n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d79ec201a347ddafe5ea96d9010562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  \n",
      "\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "\n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad51e56ce4094f9e8a280b11513ee0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch labels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ddd9951ed846e9b9012e9d2303a196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5ae8ab59104e6d81508b670a48f765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      " labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7622b3ec117d4b89ba4719cc125f9918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch labels_batch{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04cdfe730c84e9e814a04f3219c9e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      " labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch labels_batch  {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2d58ed7a20455f8ac1d4179d553fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} labels_batch \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e626c1efd5541338dacbcdacb74cd7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      " {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "labels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bc12b062424a078e5f5b50e243fbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae557f6a77e4bdf86588198db705300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a389694876d34d61bc9be0594ff05797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3447c1dbecff4826b474b68fa46199b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0417f51c87d04c23b61e08bd9c354b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batchlabels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b82f61ca7f4ce9945dc5220659248c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batchlabels_batch    {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} labels_batch\n",
      " {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch  {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6773b1d8434f1f95b91af37823ef1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batchlabels_batch   {'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batchlabels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941e5c13fe5d44cba0b90005db1d72c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch labels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      "{'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc67a0648a564efdb9aaf5164ddc8363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batchlabels_batch  {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch\n",
      " labels_batch {'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batchlabels_batch{'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}  \n",
      "{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 2, 2, 2, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 2, 6, 2, 6, 2, 6, 6, 6, 6, 2, 1, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 6, 2, 2, 1, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}labels_batch\n",
      " {'input_ids': tensor([2, 2, 1, 2, 2, 2, 6, 2, 1, 6, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6, 6, 1, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 6, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 2, 1, 2, 2, 1, 2, 6, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 6, 6, 6, 2, 2, 6, 2, 2, 4, 1, 2, 6, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 6, 6, 6, 6, 2, 6, 2, 6, 6, 2, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 4, 2, 2, 2, 6, 2, 2, 6, 2, 2, 0, 6, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194254190f0841aab029c7192860502d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([1, 6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batchlabels_batch  labels_batch  {'input_ids': tensor([0, 2, 2, 2, 2, 6, 6, 2, 6, 6, 2, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 6, 6, 2, 2, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "{'input_ids': tensor([2, 2, 6, 2, 6, 6, 6, 2, 2, 2, 2, 2, 6, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([6, 2, 6, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 6, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 6, 6, 2, 6, 6, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 1, 2, 2, 6, 2, 6, 2, 6, 4, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 2, 2, 6, 6, 2, 6, 2, 6, 2, 1, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 6, 2, 6, 6, 2, 2, 2, 6, 2, 6, 2, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2_sound_detection(hparams)\n",
    "\n",
    "trainer = pl.Trainer(gpus=1,\n",
    "                     logger=neptune_logger,\n",
    "                     max_epochs=100,\n",
    "                    overfit_batches=3,\n",
    "                    log_every_n_steps = 1)\n",
    "\n",
    "trainer.fit(model, train_dataloader, val_dataloader)\n",
    "del model, trainer # Para no ter estouro de mmoria da GPU\n",
    "#gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2_ChannelModel: ['lm_head.weight', 'wav2vec2.feature_extractor.conv_layers.6.conv.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2_ChannelModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2_ChannelModel were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in /home/cslab03/Desktop/QuakeWavNet/Results: []\n",
      "Saving checkpoints to /home/cslab03/Desktop/QuakeWavNet/Results\n"
     ]
    }
   ],
   "source": [
    "pl_model= Wav2Vec2_sound_detection(hparams=hparams)\n",
    "checkpoint_path = '/home/cslab03/Desktop/QuakeWavNet/Results/'\n",
    "checkpoint_dir = os.path.dirname(os.path.abspath(checkpoint_path))\n",
    "print(f'Files in {checkpoint_path}: {os.listdir(checkpoint_path)}')\n",
    "print(f'Saving checkpoints to {checkpoint_path}')\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(filename=hparams[\"version\"],\n",
    "                                                  dirpath=checkpoint_dir,\n",
    "                                                  save_top_k=1,\n",
    "                                                  verbose = True,\n",
    "                                                  monitor=\"val_f1\", mode=\"max\")\n",
    "early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_f1\", patience=hparams[\"patience\"], mode='max')\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "trainer = pl.Trainer(gpus=1,\n",
    "                     precision=16,\n",
    "                     logger=neptune_logger,\n",
    "                     num_sanity_val_steps=0,\n",
    "                     accumulate_grad_batches=hparams[\"accum_grads\"],\n",
    "                     enable_checkpointing=True,\n",
    "                     callbacks=[early_stop_callback, lr_monitor, checkpoint_callback],\n",
    "                     max_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA RTX A4000') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/tmp/ipykernel_6728/949965054.py:166: UnderReviewWarning: The feature LinearWarmupCosineAnnealingLR is currently marked under review. The compatibility with other Lightning projects is not guaranteed and API may change at any time. The API and functionality may change without warning in future releases. More details: https://lightning-bolts.readthedocs.io/en/latest/stability.html\n",
      "  scheduler = LinearWarmupCosineAnnealingLR(optimizer,\n",
      "\n",
      "  | Name        | Type                  | Params\n",
      "------------------------------------------------------\n",
      "0 | model       | Wav2Vec2_ChannelModel | 93.8 M\n",
      "1 | projector   | Linear                | 196 K \n",
      "2 | final_layer | Linear                | 1.8 K \n",
      "------------------------------------------------------\n",
      "94.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "94.0 M    Total params\n",
      "188.092   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e411153fc6d4990b1543c3166425294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_batch {'input_ids': tensor([6, 2, 4, 2, 6, 6, 6, 6, 6, 2, 6, 2, 6, 6, 1, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batchlabels_batch  {'input_ids': tensor([2, 2, 6, 2, 2, 2, 1, 2, 6, 2, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}{'input_ids': tensor([2, 6, 2, 6, 6, 6, 2, 1, 6, 2, 2, 6, 2, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "\n",
      "labels_batch labels_batch {'input_ids': tensor([2, 6, 2, 2, 6, 6, 6, 6, 6, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "{'input_ids': tensor([2, 2, 6, 1, 2, 6, 2, 1, 6, 6, 6, 6, 2, 2, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch labels_batch{'input_ids': tensor([6, 2, 6, 2, 2, 6, 2, 2, 2, 2, 2, 6, 2, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])} \n",
      "{'input_ids': tensor([6, 2, 1, 2, 6, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([4, 2, 6, 2, 2, 6, 2, 2, 6, 2, 6, 6, 1, 2, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 4, 2, 6, 2, 2, 6, 2, 6, 2, 6, 2, 2, 2, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 6, 2, 6, 2, 2, 6, 6, 2, 2, 2, 6, 2, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 2, 6, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 2, 2, 6, 6, 6, 2, 2, 6, 6, 6, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 2, 2, 6, 2, 2, 2, 6, 6, 2, 2, 6, 1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 2, 2, 6, 2, 2, 2, 2, 6, 2, 6, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([1, 6, 4, 6, 2, 2, 6, 2, 2, 2, 2, 2, 2, 2, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 2, 6, 2, 2, 6, 6, 6, 2, 6, 6, 2, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 2, 4, 2, 6, 2, 6, 6, 6, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 6, 2, 2, 2, 6, 6, 2, 6, 6, 2, 1, 2, 2, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 2, 6, 2, 2, 6, 2, 2, 6, 6, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 1, 2, 6, 6, 2, 6, 6, 2, 6, 2, 2, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 4, 2, 2, 2, 2, 2, 2, 6, 2, 2, 2, 6, 2, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 6, 2, 2, 2, 6, 2, 2, 2, 2, 6, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([6, 2, 6, 6, 2, 2, 2, 6, 2, 2, 6, 2, 2, 6, 2, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 6, 2, 6, 6, 2, 6, 6, 2, 2, 2, 2, 1]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 6, 6, 6, 6, 6, 2, 6, 2, 6, 2, 6, 2, 6, 2]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n",
      "labels_batch {'input_ids': tensor([2, 2, 2, 2, 2, 2, 6, 2, 2, 2, 6, 6, 0, 2, 2, 6]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_6728/419823214.py\", line 28, in __getitem__\n    feats, _ = torchaudio.load(self.audio_path + self.filenames[index])\n  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/torchaudio/backend/sox_io_backend.py\", line 256, in load\n    return _fallback_load(filepath, frame_offset, num_frames, normalize, channels_first, format)\n  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/torchaudio/backend/sox_io_backend.py\", line 30, in _fail_load\n    raise RuntimeError(\"Failed to load audio from {}\".format(filepath))\nRuntimeError: Failed to load audio from /home/cslab03/Desktop/QuakeWavNet/output/train/ed31672125758dac5313e525af133825_BHN_BTAM_LP.wav\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb Cell 33\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X43sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m val_f1_scores \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X43sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mempty_cache()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/cslab03/Desktop/QuakeWavNet/QuakeWavNet.ipynb#X43sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(pl_model, train_dataloader, val_dataloader)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_unwrap_optimized(model)\n\u001b[1;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    610\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    652\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1112\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1112\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1114\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1191\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1190\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1191\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:1214\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1214\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:267\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(dataloader, batch_to_device\u001b[39m=\u001b[39mbatch_to_device)\n\u001b[1;32m    266\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 267\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:187\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data_fetcher, DataLoaderIterDataFetcher):\n\u001b[1;32m    186\u001b[0m     batch_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 187\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(data_fetcher)\n\u001b[1;32m    188\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m     batch_idx, batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(data_fetcher)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py:184\u001b[0m, in \u001b[0;36mAbstractDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfetching_function()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py:265\u001b[0m, in \u001b[0;36mDataFetcher.fetching_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdone:\n\u001b[1;32m    263\u001b[0m     \u001b[39m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[1;32m    264\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 265\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fetch_next_batch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader_iter)\n\u001b[1;32m    266\u001b[0m         \u001b[39m# consume the batch we just fetched\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         batch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatches\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py:280\u001b[0m, in \u001b[0;36mDataFetcher._fetch_next_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    278\u001b[0m start_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_fetch_start()\n\u001b[1;32m    279\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 280\u001b[0m     batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(iterator)\n\u001b[1;32m    281\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    282\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop_profiler()\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py:571\u001b[0m, in \u001b[0;36mCombinedLoaderIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__next__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    566\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fetches the next batch from multiple data loaders.\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \n\u001b[1;32m    568\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39m        a collections of batch data\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 571\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_next_batch(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloader_iters)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py:583\u001b[0m, in \u001b[0;36mCombinedLoaderIterator.request_next_batch\u001b[0;34m(loader_iters)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    574\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest_next_batch\u001b[39m(loader_iters: Union[Iterator, Sequence, Mapping]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    575\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the batch of data from multiple iterators.\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \n\u001b[1;32m    577\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[39m        Any: a collections of batch data\u001b[39;00m\n\u001b[1;32m    582\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 583\u001b[0m     \u001b[39mreturn\u001b[39;00m apply_to_collection(loader_iters, Iterator, \u001b[39mnext\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/lightning_utilities/core/apply_func.py:51\u001b[0m, in \u001b[0;36mapply_to_collection\u001b[0;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m# Breaking condition\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, dtype) \u001b[39mand\u001b[39;00m (wrong_dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(data, wrong_dtype)):\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m function(data, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     53\u001b[0m elem_type \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(data)\n\u001b[1;32m     55\u001b[0m \u001b[39m# Recursively apply to collection items\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_6728/419823214.py\", line 28, in __getitem__\n    feats, _ = torchaudio.load(self.audio_path + self.filenames[index])\n  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/torchaudio/backend/sox_io_backend.py\", line 256, in load\n    return _fallback_load(filepath, frame_offset, num_frames, normalize, channels_first, format)\n  File \"/home/cslab03/anaconda3/envs/coEnv/lib/python3.9/site-packages/torchaudio/backend/sox_io_backend.py\", line 30, in _fail_load\n    raise RuntimeError(\"Failed to load audio from {}\".format(filepath))\nRuntimeError: Failed to load audio from /home/cslab03/Desktop/QuakeWavNet/output/train/ed31672125758dac5313e525af133825_BHN_BTAM_LP.wav\n"
     ]
    }
   ],
   "source": [
    "# Definir listas para almacenar las mtricas por poca\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_f1_scores = []\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "trainer.fit(pl_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(checkpoint_path + hparams[\"version\"]):\n",
    "    print('Saving processor to: ' + checkpoint_path + hparams[\"version\"])\n",
    "    processor.save_pretrained(checkpoint_path + hparams[\"version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback.best_model_path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Despus de completar el entrenamiento\n",
    "epochs = list(range(1, len(pl_model.val_f1_scores) + 1))\n",
    "plt.plot(epochs, pl_model.val_f1_scores, marker='o')\n",
    "plt.xlabel('poca')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('F1-score por poca')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = checkpoint_callback.best_model_path\n",
    "# best_model = \"/content/drive/MyDrive/Wav2Vec2_ORVP/wav2vec2_huggingface_fairseq_orvp_test1-epoch=4-step=23459.ckpt\"\n",
    "print(best_model)\n",
    "test_model = Wav2Vec2_sound_detection.load_from_checkpoint(best_model, hparams=hparams).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(test_model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                            collate_fn = data_collator,\n",
    "                            shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(test_model, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
